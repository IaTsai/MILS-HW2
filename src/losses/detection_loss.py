"""
æª¢æ¸¬ä»»å‹™æå¤±å‡½æ•¸
æ”¯æ´ FCOS é¢¨æ ¼çš„ anchor-free æª¢æ¸¬æå¤±ï¼ŒåŒ…å«åˆ†é¡ã€å›æ­¸å’Œä¸­å¿ƒåº¦æå¤±
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List, Optional, Tuple, Union
import math


class DetectionLoss(nn.Module):
    """
    æª¢æ¸¬ä»»å‹™æå¤±å‡½æ•¸
    
    é‡å° FCOS é¢¨æ ¼çš„ anchor-free æª¢æ¸¬è¨­è¨ˆï¼ŒåŒ…å«ï¼š
    1. Focal Loss ç”¨æ–¼åˆ†é¡
    2. IoU Loss ç”¨æ–¼é‚Šç•Œæ¡†å›æ­¸  
    3. Binary Cross Entropy ç”¨æ–¼ä¸­å¿ƒåº¦é æ¸¬
    
    Args:
        num_classes: æª¢æ¸¬é¡åˆ¥æ•¸
        alpha: Focal Loss çš„ alpha åƒæ•¸
        gamma: Focal Loss çš„ gamma åƒæ•¸
        iou_loss_type: IoU æå¤±é¡å‹ ('iou', 'giou', 'diou', 'ciou')
        center_sampling: æ˜¯å¦ä½¿ç”¨ä¸­å¿ƒåº¦æ¡æ¨£
        pos_weight: æ­£æ¨£æœ¬æ¬Šé‡
    """
    
    def __init__(self, 
                 num_classes: int = 10,
                 alpha: float = 0.25,
                 gamma: float = 2.0,
                 iou_loss_type: str = 'giou',
                 center_sampling: bool = True,
                 pos_weight: float = 1.0,
                 neg_weight: float = 1.0):
        super().__init__()
        
        self.num_classes = num_classes
        self.alpha = alpha
        self.gamma = gamma
        self.iou_loss_type = iou_loss_type
        self.center_sampling = center_sampling
        self.pos_weight = pos_weight
        self.neg_weight = neg_weight
        
        # æå¤±æ¬Šé‡
        self.cls_weight = 1.0
        self.reg_weight = 1.0
        self.centerness_weight = 1.0
    
    def focal_loss(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        """
        Focal Loss å¯¦ç¾
        
        Args:
            pred: é æ¸¬logits (B, H*W, num_classes)
            target: ç›®æ¨™æ¨™ç±¤ (B, H*W)
        
        Returns:
            focal_loss: Focal loss å€¼
        """
        # è½‰æ›ç‚ºæ¦‚ç‡
        pred_sigmoid = torch.sigmoid(pred)
        
        # å‰µå»º one-hot ç·¨ç¢¼
        target_onehot = F.one_hot(target.long(), num_classes=self.num_classes).float()
        
        # è¨ˆç®—äº¤å‰ç†µ
        ce_loss = F.binary_cross_entropy_with_logits(
            pred, target_onehot, reduction='none'
        )
        
        # è¨ˆç®— p_t
        p_t = pred_sigmoid * target_onehot + (1 - pred_sigmoid) * (1 - target_onehot)
        
        # Focal weight: (1 - p_t)^gamma
        focal_weight = (1 - p_t) ** self.gamma
        
        # Alpha weighting
        if self.alpha >= 0:
            alpha_t = self.alpha * target_onehot + (1 - self.alpha) * (1 - target_onehot)
            focal_weight = alpha_t * focal_weight
        
        # æ‡‰ç”¨ Focal weight
        focal_loss = focal_weight * ce_loss
        
        return focal_loss.sum() / (target_onehot.sum() + 1e-8)
    
    def iou_loss(self, pred_boxes: torch.Tensor, target_boxes: torch.Tensor) -> torch.Tensor:
        """
        IoU Loss å¯¦ç¾ (æ”¯æ´å¤šç¨® IoU è®Šé«”)
        
        Args:
            pred_boxes: é æ¸¬é‚Šç•Œæ¡† (N, 4) - (cx, cy, w, h)
            target_boxes: ç›®æ¨™é‚Šç•Œæ¡† (N, 4) - (cx, cy, w, h)
        
        Returns:
            iou_loss: IoU æå¤±å€¼
        """
        if pred_boxes.size(0) == 0:
            return pred_boxes.sum() * 0
        
        # Clamp box dimensions to prevent numerical issues
        # Create new tensors instead of modifying in-place
        pred_boxes_clamped = torch.zeros_like(pred_boxes)
        target_boxes_clamped = torch.zeros_like(target_boxes)
        
        # Clamp center coordinates to [0, 1]
        pred_boxes_clamped[:, 0:2] = torch.clamp(pred_boxes[:, 0:2], min=0.0, max=1.0)
        target_boxes_clamped[:, 0:2] = torch.clamp(target_boxes[:, 0:2], min=0.0, max=1.0)
        
        # Clamp width/height to [0.01, 1.0] to prevent zero or negative dimensions
        pred_boxes_clamped[:, 2:4] = torch.clamp(pred_boxes[:, 2:4], min=0.01, max=1.0)
        target_boxes_clamped[:, 2:4] = torch.clamp(target_boxes[:, 2:4], min=0.01, max=1.0)
        
        # Use clamped boxes for the rest of the computation
        pred_boxes = pred_boxes_clamped
        target_boxes = target_boxes_clamped
        
        # è½‰æ›ç‚º (x1, y1, x2, y2) æ ¼å¼
        pred_x1 = pred_boxes[:, 0] - pred_boxes[:, 2] / 2
        pred_y1 = pred_boxes[:, 1] - pred_boxes[:, 3] / 2
        pred_x2 = pred_boxes[:, 0] + pred_boxes[:, 2] / 2
        pred_y2 = pred_boxes[:, 1] + pred_boxes[:, 3] / 2
        
        target_x1 = target_boxes[:, 0] - target_boxes[:, 2] / 2
        target_y1 = target_boxes[:, 1] - target_boxes[:, 3] / 2
        target_x2 = target_boxes[:, 0] + target_boxes[:, 2] / 2
        target_y2 = target_boxes[:, 1] + target_boxes[:, 3] / 2
        
        # è¨ˆç®—äº¤é›†
        inter_x1 = torch.max(pred_x1, target_x1)
        inter_y1 = torch.max(pred_y1, target_y1)
        inter_x2 = torch.min(pred_x2, target_x2)
        inter_y2 = torch.min(pred_y2, target_y2)
        
        inter_area = torch.clamp(inter_x2 - inter_x1, min=0) * torch.clamp(inter_y2 - inter_y1, min=0)
        
        # è¨ˆç®—è¯é›†
        pred_area = (pred_x2 - pred_x1) * (pred_y2 - pred_y1)
        target_area = (target_x2 - target_x1) * (target_y2 - target_y1)
        union_area = pred_area + target_area - inter_area
        
        # åŸºæœ¬ IoU
        iou = inter_area / (union_area + 1e-8)
        
        if self.iou_loss_type == 'iou':
            return 1 - iou.mean()
        
        elif self.iou_loss_type == 'giou':
            # GIoU Loss
            enclosing_x1 = torch.min(pred_x1, target_x1)
            enclosing_y1 = torch.min(pred_y1, target_y1)
            enclosing_x2 = torch.max(pred_x2, target_x2)
            enclosing_y2 = torch.max(pred_y2, target_y2)
            
            enclosing_area = (enclosing_x2 - enclosing_x1) * (enclosing_y2 - enclosing_y1)
            giou = iou - (enclosing_area - union_area) / (enclosing_area + 1e-8)
            
            # Clamp GIoU to [-1, 1] to ensure loss is in [0, 2]
            giou = torch.clamp(giou, min=-1.0, max=1.0)
            
            return 1 - giou.mean()
        
        elif self.iou_loss_type == 'diou':
            # DIoU Loss
            center_distance_sq = (pred_boxes[:, 0] - target_boxes[:, 0]) ** 2 + \
                               (pred_boxes[:, 1] - target_boxes[:, 1]) ** 2
            
            enclosing_x1 = torch.min(pred_x1, target_x1)
            enclosing_y1 = torch.min(pred_y1, target_y1)
            enclosing_x2 = torch.max(pred_x2, target_x2)
            enclosing_y2 = torch.max(pred_y2, target_y2)
            
            diagonal_distance_sq = (enclosing_x2 - enclosing_x1) ** 2 + (enclosing_y2 - enclosing_y1) ** 2
            
            diou = iou - center_distance_sq / (diagonal_distance_sq + 1e-8)
            
            return 1 - diou.mean()
        
        elif self.iou_loss_type == 'ciou':
            # CIoU Loss  
            center_distance_sq = (pred_boxes[:, 0] - target_boxes[:, 0]) ** 2 + \
                               (pred_boxes[:, 1] - target_boxes[:, 1]) ** 2
            
            enclosing_x1 = torch.min(pred_x1, target_x1)
            enclosing_y1 = torch.min(pred_y1, target_y1)
            enclosing_x2 = torch.max(pred_x2, target_x2)
            enclosing_y2 = torch.max(pred_y2, target_y2)
            
            diagonal_distance_sq = (enclosing_x2 - enclosing_x1) ** 2 + (enclosing_y2 - enclosing_y1) ** 2
            
            # ç¸±æ©«æ¯”ä¸€è‡´æ€§
            v = (4 / (math.pi ** 2)) * torch.pow(
                torch.atan(target_boxes[:, 2] / (target_boxes[:, 3] + 1e-8)) - 
                torch.atan(pred_boxes[:, 2] / (pred_boxes[:, 3] + 1e-8)), 2
            )
            
            alpha = v / (1 - iou + v + 1e-8)
            
            ciou = iou - center_distance_sq / (diagonal_distance_sq + 1e-8) - alpha * v
            
            return 1 - ciou.mean()
        
        else:
            raise ValueError(f"Unsupported IoU loss type: {self.iou_loss_type}")
    
    def centerness_loss(self, pred_centerness: torch.Tensor, target_centerness: torch.Tensor) -> torch.Tensor:
        """
        ä¸­å¿ƒåº¦æå¤± (Binary Cross Entropy)
        
        Args:
            pred_centerness: é æ¸¬ä¸­å¿ƒåº¦ (N,)
            target_centerness: ç›®æ¨™ä¸­å¿ƒåº¦ (N,)
        
        Returns:
            centerness_loss: ä¸­å¿ƒåº¦æå¤±
        """
        if pred_centerness.size(0) == 0:
            return pred_centerness.sum() * 0
        
        return F.binary_cross_entropy_with_logits(
            pred_centerness, target_centerness, reduction='mean'
        )
    
    def forward(self, 
                predictions: torch.Tensor, 
                targets: List[Dict[str, torch.Tensor]]) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
        """
        å‰å‘å‚³æ’­
        
        Args:
            predictions: æ¨¡å‹é æ¸¬ (B, H*W, 6) - (cx, cy, w, h, centerness, class)
            targets: ç›®æ¨™æ¨™ç±¤åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ åŒ…å« 'boxes', 'labels'
        
        Returns:
            total_loss: ç¸½æå¤±
            loss_dict: è©³ç´°æå¤±å­—å…¸
        """
        device = predictions.device
        batch_size = predictions.size(0)
        
        # è§£æé æ¸¬ - æ ¹æ“šå¯¦éš›æ¨¡å‹è¼¸å‡ºæ ¼å¼èª¿æ•´
        # å¦‚æœè¼¸å…¥æ˜¯15ç¶­ [boxes(4), classes(10), centerness(1)]
        if predictions.size(-1) == 15:
            pred_boxes = predictions[..., :4]           # (B, H*W, 4)
            pred_classes = predictions[..., 4:14]       # (B, H*W, 10)
            pred_centerness = predictions[..., 14]      # (B, H*W)
        else:
            # åŸå§‹æ ¼å¼ [boxes(4), centerness(1), class(1 or num_classes)]
            pred_boxes = predictions[..., :4]        # (B, H*W, 4)
            pred_centerness = predictions[..., 4]    # (B, H*W)
            pred_classes = predictions[..., 5:]      # (B, H*W, 1) æˆ–è€… logits
        
        # å°é æ¸¬çš„é‚Šç•Œæ¡†æ‡‰ç”¨ sigmoid ä»¥ç¢ºä¿åœ¨ [0, 1] ç¯„åœå…§
        pred_boxes = torch.sigmoid(pred_boxes)
        
        # å¦‚æœé æ¸¬é¡åˆ¥æ˜¯å–®ä¸€æ•¸å€¼ï¼Œè½‰æ›ç‚º logits
        if pred_classes.size(-1) == 1:
            # å‡è¨­é€™æ˜¯é¡åˆ¥ç´¢å¼•ï¼Œè½‰æ›ç‚º one-hot æˆ–è€…æ“´å±•ç‚º logits
            pred_classes = pred_classes.squeeze(-1)  # (B, H*W)
            # å‰µå»ºå½ logits (ç°¡åŒ–è™•ç†)
            pred_logits = torch.zeros(batch_size, pred_classes.size(1), self.num_classes).to(device)
            for b in range(batch_size):
                for i in range(pred_classes.size(1)):
                    class_idx = pred_classes[b, i].long()
                    if 0 <= class_idx < self.num_classes:
                        # Create a new tensor instead of in-place modification
                        one_hot = torch.zeros_like(pred_logits[b, i])
                        one_hot[class_idx] = 1.0
                        pred_logits = pred_logits.clone()
                        pred_logits[b, i] = one_hot
        else:
            pred_logits = pred_classes
        
        # åˆå§‹åŒ–æå¤±
        total_cls_loss = 0
        total_reg_loss = 0
        total_centerness_loss = 0
        
        num_positive_samples = 0
        
        for batch_idx in range(batch_size):
            if batch_idx < len(targets) and targets[batch_idx] is not None:
                # è§£æç›®æ¨™
                target_dict = targets[batch_idx]
                if 'boxes' in target_dict and 'labels' in target_dict:
                    target_boxes = target_dict['boxes']      # (N, 4)
                    target_labels = target_dict['labels']    # (N,)
                    
                    if target_boxes.size(0) > 0:
                        # ç°¡åŒ–çš„æ­£è² æ¨£æœ¬åˆ†é… (å¯¦éš›æ‡‰è©²åŸºæ–¼è·é›¢æˆ–IoU)
                        # é€™è£¡å‡è¨­å‰ N å€‹é æ¸¬å°æ‡‰ N å€‹ç›®æ¨™
                        num_targets = min(target_boxes.size(0), pred_boxes.size(1))
                        
                        if num_targets > 0:
                            # åˆ†é¡æå¤±
                            batch_pred_logits = pred_logits[batch_idx, :num_targets]  # (N, num_classes)
                            batch_target_labels = target_labels[:num_targets]         # (N,)
                            
                            cls_loss = self.focal_loss(batch_pred_logits.unsqueeze(0), 
                                                     batch_target_labels.unsqueeze(0))
                            total_cls_loss += cls_loss
                            
                            # å›æ­¸æå¤±
                            batch_pred_boxes = pred_boxes[batch_idx, :num_targets]    # (N, 4)
                            batch_target_boxes = target_boxes[:num_targets]          # (N, 4)
                            
                            # ç¢ºä¿ç›®æ¨™æ¡†ä¹Ÿåœ¨ [0, 1] ç¯„åœå…§
                            batch_target_boxes = torch.clamp(batch_target_boxes, min=0.0, max=1.0)
                            
                            reg_loss = self.iou_loss(batch_pred_boxes, batch_target_boxes)
                            total_reg_loss += reg_loss
                            
                            # ä¸­å¿ƒåº¦æå¤± (ç°¡åŒ–ï¼šä½¿ç”¨IoUä½œç‚ºç›®æ¨™ä¸­å¿ƒåº¦)
                            with torch.no_grad():
                                # è¨ˆç®—ç›®æ¨™ä¸­å¿ƒåº¦ (åŸºæ–¼IoU)
                                target_centerness = self._compute_centerness_targets(
                                    batch_pred_boxes, batch_target_boxes
                                )
                            
                            batch_pred_centerness = pred_centerness[batch_idx, :num_targets]
                            centerness_loss = self.centerness_loss(batch_pred_centerness, target_centerness)
                            total_centerness_loss += centerness_loss
                            
                            num_positive_samples += num_targets
        
        # å¹³å‡åŒ–æå¤±
        if num_positive_samples > 0:
            total_cls_loss = total_cls_loss / batch_size
            total_reg_loss = total_reg_loss / batch_size
            total_centerness_loss = total_centerness_loss / batch_size
        else:
            # æ²’æœ‰æ­£æ¨£æœ¬æ™‚ï¼Œåªè¨ˆç®—åˆ†é¡æå¤± (èƒŒæ™¯é¡)
            total_cls_loss = self.focal_loss(pred_logits, torch.zeros_like(pred_logits[..., 0]).long())
            total_reg_loss = pred_boxes.sum() * 0
            total_centerness_loss = pred_centerness.sum() * 0
        
        # åŠ æ¬Šç¸½æå¤±
        total_loss = (self.cls_weight * total_cls_loss + 
                     self.reg_weight * total_reg_loss + 
                     self.centerness_weight * total_centerness_loss)
        
        # ç¢ºä¿æå¤±éè² 
        total_loss = torch.clamp(total_loss, min=0.0)
        
        loss_dict = {
            'classification': total_cls_loss,
            'regression': total_reg_loss,
            'centerness': total_centerness_loss,
            'total': total_loss
        }
        
        return total_loss, loss_dict
    
    def _compute_centerness_targets(self, pred_boxes: torch.Tensor, target_boxes: torch.Tensor) -> torch.Tensor:
        """
        è¨ˆç®—ä¸­å¿ƒåº¦ç›®æ¨™ (åŸºæ–¼IoU)
        
        Args:
            pred_boxes: é æ¸¬é‚Šç•Œæ¡† (N, 4)
            target_boxes: ç›®æ¨™é‚Šç•Œæ¡† (N, 4)
        
        Returns:
            centerness_targets: ä¸­å¿ƒåº¦ç›®æ¨™ (N,)
        """
        # ç°¡åŒ–ï¼šä½¿ç”¨IoUä½œç‚ºä¸­å¿ƒåº¦ç›®æ¨™
        ious = self._compute_ious(pred_boxes, target_boxes)
        return torch.sqrt(torch.clamp(ious, min=0, max=1))
    
    def _compute_ious(self, boxes1: torch.Tensor, boxes2: torch.Tensor) -> torch.Tensor:
        """
        è¨ˆç®—å…©çµ„é‚Šç•Œæ¡†çš„IoU
        
        Args:
            boxes1: é‚Šç•Œæ¡†1 (N, 4) - (cx, cy, w, h)
            boxes2: é‚Šç•Œæ¡†2 (N, 4) - (cx, cy, w, h)
        
        Returns:
            ious: IoUå€¼ (N,)
        """
        # è½‰æ›ç‚º (x1, y1, x2, y2)
        boxes1_x1 = boxes1[:, 0] - boxes1[:, 2] / 2
        boxes1_y1 = boxes1[:, 1] - boxes1[:, 3] / 2
        boxes1_x2 = boxes1[:, 0] + boxes1[:, 2] / 2
        boxes1_y2 = boxes1[:, 1] + boxes1[:, 3] / 2
        
        boxes2_x1 = boxes2[:, 0] - boxes2[:, 2] / 2
        boxes2_y1 = boxes2[:, 1] - boxes2[:, 3] / 2
        boxes2_x2 = boxes2[:, 0] + boxes2[:, 2] / 2
        boxes2_y2 = boxes2[:, 1] + boxes2[:, 3] / 2
        
        # è¨ˆç®—äº¤é›†
        inter_x1 = torch.max(boxes1_x1, boxes2_x1)
        inter_y1 = torch.max(boxes1_y1, boxes2_y1)
        inter_x2 = torch.min(boxes1_x2, boxes2_x2)
        inter_y2 = torch.min(boxes1_y2, boxes2_y2)
        
        inter_area = torch.clamp(inter_x2 - inter_x1, min=0) * torch.clamp(inter_y2 - inter_y1, min=0)
        
        # è¨ˆç®—è¯é›†
        area1 = (boxes1_x2 - boxes1_x1) * (boxes1_y2 - boxes1_y1)
        area2 = (boxes2_x2 - boxes2_x1) * (boxes2_y2 - boxes2_y1)
        union_area = area1 + area2 - inter_area
        
        return inter_area / (union_area + 1e-8)


def create_detection_loss(num_classes: int = 10, 
                         loss_type: str = 'fcos',
                         **kwargs) -> DetectionLoss:
    """
    æª¢æ¸¬æå¤±å·¥å» å‡½æ•¸
    
    Args:
        num_classes: æª¢æ¸¬é¡åˆ¥æ•¸
        loss_type: æå¤±é¡å‹
        **kwargs: å…¶ä»–åƒæ•¸
    
    Returns:
        detection_loss: æª¢æ¸¬æå¤±å‡½æ•¸
    """
    if loss_type == 'fcos':
        return DetectionLoss(num_classes=num_classes, **kwargs)
    else:
        raise ValueError(f"Unsupported detection loss type: {loss_type}")


if __name__ == "__main__":
    # æ¸¬è©¦ä»£ç¢¼
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # å‰µå»ºæª¢æ¸¬æå¤±
    det_loss = create_detection_loss(num_classes=10, iou_loss_type='giou')
    
    # æ¨¡æ“¬é æ¸¬å’Œç›®æ¨™
    batch_size = 2
    num_predictions = 100
    
    # é æ¸¬: (B, H*W, 6) - (cx, cy, w, h, centerness, class)
    predictions = torch.randn(batch_size, num_predictions, 6).to(device)
    predictions[..., :4] = torch.sigmoid(predictions[..., :4])  # æ­¸ä¸€åŒ–åæ¨™
    predictions[..., 5] = torch.randint(0, 10, (batch_size, num_predictions)).float()  # é¡åˆ¥
    
    # ç›®æ¨™
    targets = []
    for b in range(batch_size):
        num_objects = torch.randint(1, 5, (1,)).item()
        target = {
            'boxes': torch.rand(num_objects, 4).to(device),  # (cx, cy, w, h)
            'labels': torch.randint(0, 10, (num_objects,)).to(device)
        }
        targets.append(target)
    
    # è¨ˆç®—æå¤±
    total_loss, loss_dict = det_loss(predictions, targets)
    
    print("âœ… æª¢æ¸¬æå¤±æ¸¬è©¦æˆåŠŸï¼")
    print(f"ğŸ“Š ç¸½æå¤±: {total_loss.item():.4f}")
    print(f"ğŸ” è©³ç´°æå¤±: {loss_dict}")
    print(f"ğŸ“ˆ æå¤±é …: {list(loss_dict.keys())}")