"""
Elastic Weight Consolidation (EWC) å¯¦ç¾ - ä¿®å¾©ç‰ˆæœ¬
ä¿®å¾©äº†æ•¸å€¼ç©©å®šæ€§å•é¡Œï¼Œé˜²æ­¢ç½é›£æ€§éºå¿˜

åŸºæ–¼è«–æ–‡: "Overcoming catastrophic forgetting in neural networks"
(Kirkpatrick et al., 2017)

ä¸»è¦ä¿®å¾©:
1. FisherçŸ©é™£è¨ˆç®—ä½¿ç”¨å¹³å‡è€Œéç¸½å’Œ
2. æ·»åŠ æ¢¯åº¦è£å‰ªå’Œæ•¸å€¼ç©©å®šæ€§æªæ–½
3. Fisherå€¼ç¯„åœé™åˆ¶é˜²æ­¢çˆ†ç‚¸
4. æ›´åˆç†çš„importanceæ¬Šé‡ç¯„åœ
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from typing import Dict, List, Optional, Tuple, Any, Union
import copy
import time
import numpy as np
from collections import defaultdict


class EWC:
    """
    Elastic Weight Consolidation (EWC) å¯¦ç¾ - å¢å¼·ç‰ˆ
    
    ä¸»è¦æ”¹é€²:
    1. ä¿®å¾©FisherçŸ©é™£è¨ˆç®—ä¸­çš„æ¦‚ç‡æ±‚å’ŒéŒ¯èª¤
    2. æ·»åŠ æ•¸å€¼ç©©å®šæ€§æªæ–½
    3. æ”¯æ´å‹•æ…‹æ¬Šé‡èª¿æ•´
    4. é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
    """
    
    def __init__(self, 
                 model: nn.Module,
                 importance: float = 5000.0,  # æå‡åˆå§‹æ¬Šé‡
                 device: Optional[torch.device] = None,
                 diagonal_only: bool = True,
                 ewc_type: str = 'l2',
                 max_fisher_value: float = 1e6,  # Fisherå€¼ä¸Šé™
                 eps: float = 1e-8):  # æ•¸å€¼ç©©å®šæ€§epsilon
        
        self.model = model
        self.importance = importance
        self.device = device if device is not None else next(model.parameters()).device
        self.diagonal_only = diagonal_only
        self.ewc_type = ewc_type
        self.max_fisher_value = max_fisher_value
        self.eps = eps
        
        # å­˜å„² Fisher ä¿¡æ¯çŸ©é™£å’Œæœ€å„ªåƒæ•¸
        self.fisher_matrices = {}
        self.optimal_params = {}
        self.task_count = 0
        
        # Online EWC çš„é¡å¤–åƒæ•¸
        if ewc_type == 'online':
            self.gamma = 0.9  # è¡°æ¸›å› å­ï¼Œé™ä½ä»¥æ¸›å°‘èˆŠä»»å‹™å½±éŸ¿
            self.consolidated_fisher = {}
            self.consolidated_params = {}
        
        # åƒæ•¸åç¨±æ˜ å°„
        self.param_names = [name for name, _ in model.named_parameters() if _.requires_grad]
        
        # çµ±è¨ˆä¿¡æ¯
        self.computation_stats = {
            'fisher_computation_time': [],
            'penalty_computation_time': [],
            'memory_usage': [],
            'fisher_magnitudes': []  # æ–°å¢ï¼šè¿½è¹¤Fisherå€¼å¤§å°
        }
        
        # è‡ªé©æ‡‰æ¬Šé‡èª¿æ•´
        self.adaptive_importance = importance
        self.importance_history = [importance]
        self.forgetting_rates = []
    
    def _get_named_parameters(self) -> Dict[str, torch.Tensor]:
        """ç²å–æ¨¡å‹çš„å‘½ååƒæ•¸å­—å…¸"""
        return {name: param for name, param in self.model.named_parameters() if param.requires_grad}
    
    def compute_fisher_matrix(self, 
                            dataloader: DataLoader,
                            task_id: Optional[int] = None,
                            num_samples: Optional[int] = None,
                            verbose: bool = True) -> Dict[str, torch.Tensor]:
        """
        è¨ˆç®— Fisher ä¿¡æ¯çŸ©é™£ - ä¿®å¾©ç‰ˆæœ¬
        """
        if task_id is None:
            task_id = self.task_count
        
        if verbose:
            print(f"ğŸ§® è¨ˆç®—ä»»å‹™ {task_id} çš„ Fisher ä¿¡æ¯çŸ©é™£...")
        
        start_time = time.time()
        
        # è¨­ç½®æ¨¡å‹ç‚ºè©•ä¼°æ¨¡å¼
        self.model.eval()
        
        # åˆå§‹åŒ– Fisher çŸ©é™£å’Œè¨ˆæ•¸å™¨
        fisher_matrix = {}
        fisher_counts = {}  # è¨˜éŒ„æ¯å€‹åƒæ•¸çš„æ¨£æœ¬æ•¸
        for name, param in self._get_named_parameters().items():
            fisher_matrix[name] = torch.zeros_like(param.data)
            fisher_counts[name] = 0
        
        # æ¨£æœ¬è¨ˆæ•¸
        sample_count = 0
        total_samples = len(dataloader.dataset) if num_samples is None else min(num_samples, len(dataloader.dataset))
        
        if verbose:
            print(f"  ä½¿ç”¨ {total_samples} å€‹æ¨£æœ¬è¨ˆç®— Fisher çŸ©é™£")
        
        # æ‰¹æ¬¡è™•ç†
        for batch_idx, batch in enumerate(dataloader):
            if num_samples is not None and sample_count >= num_samples:
                break
            
            # è§£ææ‰¹æ¬¡æ•¸æ“š
            if isinstance(batch, dict):
                # Try both 'image' and 'images' keys
                if 'image' in batch:
                    images = batch['image'].to(self.device)
                elif 'images' in batch:
                    images = batch['images'].to(self.device)
                else:
                    raise KeyError("Batch dict must contain 'image' or 'images' key")
                batch_size = images.size(0)
            elif isinstance(batch, (list, tuple)) and len(batch) >= 2:
                images = batch[0].to(self.device)
                batch_size = images.size(0)
            else:
                images = batch.to(self.device)
                batch_size = images.size(0)
            
            # å‰å‘å‚³æ’­
            outputs = self.model(images)
            
            # è™•ç†å¤šä»»å‹™è¼¸å‡º
            if isinstance(outputs, dict):
                # å¤šä»»å‹™è¼¸å‡ºï¼šè¨ˆç®—æ¯å€‹ä»»å‹™çš„ Fisher çŸ©é™£
                for task_name, task_output in outputs.items():
                    self._accumulate_fisher_from_output_fixed(
                        task_output, fisher_matrix, fisher_counts, batch_size
                    )
            else:
                # å–®ä»»å‹™è¼¸å‡º
                self._accumulate_fisher_from_output_fixed(
                    outputs, fisher_matrix, fisher_counts, batch_size
                )
            
            sample_count += batch_size
            
            if verbose and (batch_idx + 1) % 50 == 0:
                progress = min(sample_count / total_samples * 100, 100)
                print(f"  é€²åº¦: {progress:.1f}% ({sample_count}/{total_samples})")
        
        # æ­£è¦åŒ– Fisher çŸ©é™£ - ä½¿ç”¨å¯¦éš›çš„è¨ˆæ•¸
        for name in fisher_matrix:
            if fisher_counts[name] > 0:
                fisher_matrix[name] = fisher_matrix[name] / fisher_counts[name]
                
                # æ‡‰ç”¨Fisherå€¼ä¸Šé™é˜²æ­¢çˆ†ç‚¸
                fisher_matrix[name] = torch.clamp(
                    fisher_matrix[name], 
                    min=0, 
                    max=self.max_fisher_value
                )
        
        # å­˜å„² Fisher çŸ©é™£
        self.fisher_matrices[task_id] = fisher_matrix
        
        # è¨˜éŒ„è¨ˆç®—æ™‚é–“å’Œçµ±è¨ˆ
        computation_time = time.time() - start_time
        self.computation_stats['fisher_computation_time'].append(computation_time)
        
        # è¨˜éŒ„Fisherå€¼å¤§å°
        avg_fisher = sum(f.mean().item() for f in fisher_matrix.values()) / len(fisher_matrix)
        max_fisher = max(f.max().item() for f in fisher_matrix.values())
        self.computation_stats['fisher_magnitudes'].append({
            'avg': avg_fisher,
            'max': max_fisher
        })
        
        if verbose:
            print(f"  âœ… Fisher çŸ©é™£è¨ˆç®—å®Œæˆ (è€—æ™‚: {computation_time:.2f}s)")
            print(f"  ğŸ“Š å¹³å‡Fisherå€¼: {avg_fisher:.6f}")
            print(f"  ğŸ“Š æœ€å¤§Fisherå€¼: {max_fisher:.6f}")
        
        return fisher_matrix
    
    def _accumulate_fisher_from_output_fixed(self, 
                                           output: torch.Tensor, 
                                           fisher_matrix: Dict[str, torch.Tensor],
                                           fisher_counts: Dict[str, int],
                                           batch_size: int):
        """
        å¾æ¨¡å‹è¼¸å‡ºç´¯ç© Fisher ä¿¡æ¯çŸ©é™£ - ä¿®å¾©ç‰ˆæœ¬
        
        ä¸»è¦ä¿®å¾©:
        1. ä½¿ç”¨å¹³å‡è€Œéç¸½å’Œè¨ˆç®—æ¦‚ç‡æ¬Šé‡
        2. æ·»åŠ æ¢¯åº¦è£å‰ª
        3. æ­£ç¢ºè™•ç†ä¸åŒç¶­åº¦çš„è¼¸å‡º
        """
        # æ¸…é›¶æ¢¯åº¦
        self.model.zero_grad()
        
        # è¨ˆç®—å°æ•¸ä¼¼ç„¶æ¢¯åº¦
        if output.dim() == 2:
            # åˆ†é¡ä»»å‹™ï¼šæ‰¹æ¬¡è¼¸å‡º (B, C)
            log_prob = F.log_softmax(output, dim=1)
            prob = F.softmax(output, dim=1)
            num_samples = output.size(0)
            
        elif output.dim() == 4:
            # åˆ†å‰²ä»»å‹™ï¼š(B, C, H, W)
            B, C, H, W = output.shape
            output_flat = output.view(B, C, -1).transpose(1, 2).contiguous().view(-1, C)
            log_prob = F.log_softmax(output_flat, dim=1)
            prob = F.softmax(output_flat, dim=1)
            num_samples = B * H * W
            
        elif output.dim() == 3:
            # æª¢æ¸¬ä»»å‹™ï¼š(B, N, C)
            B, N, C = output.shape
            output_flat = output.view(-1, C)
            log_prob = F.log_softmax(output_flat, dim=1)
            prob = F.softmax(output_flat, dim=1)
            num_samples = B * N
        else:
            raise ValueError(f"Unsupported output dimension: {output.dim()}")
        
        # è¨ˆç®—æœŸæœ›çš„ Fisher ä¿¡æ¯çŸ©é™£
        for class_idx in range(prob.size(1)):
            # ä½¿ç”¨å¹³å‡æ¦‚ç‡è€Œéç¸½å’Œ
            class_prob_mean = prob[:, class_idx].mean()
            
            if class_prob_mean.item() > self.eps:  # é¿å…æ•¸å€¼ä¸ç©©å®š
                # é¸æ“‡è©²é¡åˆ¥çš„å°æ•¸æ¦‚ç‡ä¸¦è¨ˆç®—æ¢¯åº¦
                class_log_prob = log_prob[:, class_idx].mean()
                class_log_prob.backward(retain_graph=True)
                
                # ç´¯ç© Fisher ä¿¡æ¯
                for name, param in self._get_named_parameters().items():
                    if param.grad is not None:
                        # æ¢¯åº¦è£å‰ªé˜²æ­¢çˆ†ç‚¸
                        grad_data = torch.clamp(param.grad.data, -10, 10)
                        
                        # å°è§’ Fisher çŸ©é™£
                        fisher_update = class_prob_mean.item() * (grad_data ** 2)
                        fisher_matrix[name] += fisher_update
                        fisher_counts[name] += 1
                
                # æ¸…é›¶æ¢¯åº¦
                self.model.zero_grad()
    
    def store_optimal_params(self, task_id: Optional[int] = None):
        """å­˜å„²ç•¶å‰ä»»å‹™çš„æœ€å„ªåƒæ•¸"""
        if task_id is None:
            task_id = self.task_count
        
        optimal_params = {}
        for name, param in self._get_named_parameters().items():
            optimal_params[name] = param.data.clone()
        
        self.optimal_params[task_id] = optimal_params
        print(f"ğŸ“¥ å­˜å„²ä»»å‹™ {task_id} çš„æœ€å„ªåƒæ•¸")
    
    def penalty(self, model: Optional[nn.Module] = None) -> torch.Tensor:
        """
        è¨ˆç®— EWC æ‡²ç½°é … - å¢å¼·ç‰ˆæœ¬
        
        æ”¹é€²:
        1. æ·»åŠ æ‡²ç½°é …ç¯„åœé™åˆ¶
        2. ä½¿ç”¨è‡ªé©æ‡‰æ¬Šé‡
        3. é˜²æ­¢æ•¸å€¼æº¢å‡º
        """
        if model is None:
            model = self.model
        
        start_time = time.time()
        
        penalty = 0.0
        current_params = {name: param for name, param in model.named_parameters() if param.requires_grad}
        
        if self.ewc_type == 'l2':
            # æ¨™æº– EWC: å°æ‰€æœ‰ä»»å‹™è¨ˆç®—æ‡²ç½°é …
            for task_id in self.fisher_matrices.keys():
                if task_id in self.optimal_params:
                    task_penalty = self._compute_task_penalty_safe(
                        current_params, 
                        self.fisher_matrices[task_id], 
                        self.optimal_params[task_id]
                    )
                    penalty += task_penalty
        
        elif self.ewc_type == 'online':
            # Online EWC: ä½¿ç”¨åˆä½µçš„ Fisher çŸ©é™£
            if self.consolidated_fisher and self.consolidated_params:
                penalty = self._compute_task_penalty_safe(
                    current_params,
                    self.consolidated_fisher,
                    self.consolidated_params
                )
        
        # ä½¿ç”¨è‡ªé©æ‡‰æ¬Šé‡
        penalty_tensor = torch.tensor(penalty, device=self.device, requires_grad=True)
        penalty_loss = self.adaptive_importance * penalty_tensor
        
        # é˜²æ­¢æ‡²ç½°é …çˆ†ç‚¸
        penalty_loss = torch.clamp(penalty_loss, max=1e10)
        
        # è¨˜éŒ„è¨ˆç®—æ™‚é–“
        computation_time = time.time() - start_time
        self.computation_stats['penalty_computation_time'].append(computation_time)
        
        return penalty_loss
    
    def _compute_task_penalty_safe(self, 
                                 current_params: Dict[str, torch.Tensor],
                                 fisher_matrix: Dict[str, torch.Tensor],
                                 optimal_params: Dict[str, torch.Tensor]) -> float:
        """
        è¨ˆç®—å–®å€‹ä»»å‹™çš„æ‡²ç½°é … - å®‰å…¨ç‰ˆæœ¬
        """
        task_penalty = 0.0
        
        for name in fisher_matrix.keys():
            if name in current_params and name in optimal_params:
                # åƒæ•¸å·®ç•°
                param_diff = current_params[name] - optimal_params[name]
                
                # å°è§’ Fisher çŸ©é™£
                fisher_diag = fisher_matrix[name]
                
                # æ·»åŠ æ•¸å€¼ç©©å®šæ€§
                fisher_diag = torch.clamp(fisher_diag, min=0, max=self.max_fisher_value)
                
                penalty_term = fisher_diag * (param_diff ** 2)
                task_penalty += penalty_term.sum().item()
        
        return task_penalty / 2.0
    
    def update_adaptive_importance(self, forgetting_rate: float, target_rate: float = 0.05):
        """
        æ ¹æ“šéºå¿˜ç‡å‹•æ…‹èª¿æ•´EWCæ¬Šé‡
        
        Args:
            forgetting_rate: ç•¶å‰éºå¿˜ç‡
            target_rate: ç›®æ¨™éºå¿˜ç‡
        """
        self.forgetting_rates.append(forgetting_rate)
        
        # å¦‚æœéºå¿˜ç‡è¶…éç›®æ¨™ï¼Œå¢åŠ æ¬Šé‡
        if forgetting_rate > target_rate:
            # æŒ‡æ•¸å¢é•·ï¼Œå¿«é€ŸéŸ¿æ‡‰é«˜éºå¿˜ç‡
            scale_factor = min(2.0, 1.0 + (forgetting_rate - target_rate) * 10)
            self.adaptive_importance = min(
                self.adaptive_importance * scale_factor, 
                100000.0  # ä¸Šé™
            )
        else:
            # ç·©æ…¢é™ä½æ¬Šé‡
            self.adaptive_importance *= 0.95
        
        self.importance_history.append(self.adaptive_importance)
        
        print(f"ğŸ”§ è‡ªé©æ‡‰EWCæ¬Šé‡èª¿æ•´: {self.adaptive_importance:.1f} (éºå¿˜ç‡: {forgetting_rate:.2%})")
    
    def update_consolidated_fisher(self):
        """æ›´æ–°åˆä½µçš„ Fisher çŸ©é™£ (ç”¨æ–¼ Online EWC)"""
        if self.ewc_type != 'online':
            return
        
        if not self.fisher_matrices:
            return
        
        # ç²å–æœ€æ–°çš„ Fisher çŸ©é™£å’Œåƒæ•¸
        latest_task_id = max(self.fisher_matrices.keys())
        latest_fisher = self.fisher_matrices[latest_task_id]
        latest_params = self.optimal_params[latest_task_id]
        
        if not self.consolidated_fisher:
            # ç¬¬ä¸€å€‹ä»»å‹™ï¼šç›´æ¥è¤‡è£½
            self.consolidated_fisher = copy.deepcopy(latest_fisher)
            self.consolidated_params = copy.deepcopy(latest_params)
        else:
            # å¾ŒçºŒä»»å‹™ï¼šåŠ æ¬Šåˆä½µ
            for name in latest_fisher.keys():
                if name in self.consolidated_fisher:
                    # åˆä½µ Fisher çŸ©é™£
                    self.consolidated_fisher[name] = (
                        self.gamma * self.consolidated_fisher[name] + 
                        latest_fisher[name]
                    )
                    
                    # é™åˆ¶åˆä½µå¾Œçš„Fisherå€¼
                    self.consolidated_fisher[name] = torch.clamp(
                        self.consolidated_fisher[name],
                        max=self.max_fisher_value
                    )
                    
                    # æ›´æ–°åˆä½µåƒæ•¸
                    weight_old = self.gamma / (self.gamma + 1.0)
                    weight_new = 1.0 / (self.gamma + 1.0)
                    self.consolidated_params[name] = (
                        weight_old * self.consolidated_params[name] + 
                        weight_new * latest_params[name]
                    )
        
        print(f"ğŸ”„ æ›´æ–°åˆä½µçš„ Fisher çŸ©é™£ (ä»»å‹™ {latest_task_id})")
    
    def finish_task(self, 
                   dataloader: DataLoader, 
                   task_id: Optional[int] = None,
                   verbose: bool = True) -> int:
        """å®Œæˆç•¶å‰ä»»å‹™çš„ EWC è¨­ç½®"""
        if task_id is None:
            task_id = self.task_count
        
        if verbose:
            print(f"ğŸ¯ å®Œæˆä»»å‹™ {task_id} çš„ EWC è¨­ç½®...")
            print(f"  ç•¶å‰è‡ªé©æ‡‰æ¬Šé‡: {self.adaptive_importance:.1f}")
        
        # è¨ˆç®— Fisher çŸ©é™£
        self.compute_fisher_matrix(dataloader, task_id=task_id, verbose=verbose)
        
        # å­˜å„²æœ€å„ªåƒæ•¸
        self.store_optimal_params(task_id=task_id)
        
        # æ›´æ–°åˆä½µçš„ Fisher çŸ©é™£ (Online EWC)
        if self.ewc_type == 'online':
            self.update_consolidated_fisher()
        
        # å¢åŠ ä»»å‹™è¨ˆæ•¸
        if task_id == self.task_count:
            self.task_count += 1
        
        if verbose:
            print(f"âœ… ä»»å‹™ {task_id} çš„ EWC è¨­ç½®å®Œæˆ")
            memory_info = self.get_memory_usage()
            print(f"  ğŸ’¾ è¨˜æ†¶é«”ä½¿ç”¨: {memory_info['total_mb']:.2f} MB")
        
        return task_id
    
    def get_memory_usage(self) -> Dict[str, float]:
        """ç²å– EWC çš„è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³"""
        fisher_memory = 0
        params_memory = 0
        
        # è¨ˆç®— Fisher çŸ©é™£è¨˜æ†¶é«”
        for fisher_matrix in self.fisher_matrices.values():
            for tensor in fisher_matrix.values():
                fisher_memory += tensor.numel() * tensor.element_size()
        
        # è¨ˆç®—åƒæ•¸è¨˜æ†¶é«”
        for params in self.optimal_params.values():
            for tensor in params.values():
                params_memory += tensor.numel() * tensor.element_size()
        
        # åˆä½µçš„ Fisher çŸ©é™£è¨˜æ†¶é«”
        consolidated_memory = 0
        if hasattr(self, 'consolidated_fisher') and self.consolidated_fisher:
            for tensor in self.consolidated_fisher.values():
                consolidated_memory += tensor.numel() * tensor.element_size()
        
        total_memory = fisher_memory + params_memory + consolidated_memory
        
        memory_info = {
            'fisher_matrices_mb': fisher_memory / (1024 ** 2),
            'optimal_params_mb': params_memory / (1024 ** 2),
            'consolidated_mb': consolidated_memory / (1024 ** 2),
            'total_mb': total_memory / (1024 ** 2),
            'num_tasks': len(self.fisher_matrices)
        }
        
        return memory_info
    
    def get_computation_stats(self) -> Dict[str, Any]:
        """ç²å–è¨ˆç®—çµ±è¨ˆä¿¡æ¯"""
        stats = {
            'avg_fisher_time': np.mean(self.computation_stats['fisher_computation_time']) if self.computation_stats['fisher_computation_time'] else 0,
            'avg_penalty_time': np.mean(self.computation_stats['penalty_computation_time']) if self.computation_stats['penalty_computation_time'] else 0,
            'total_fisher_computations': len(self.computation_stats['fisher_computation_time']),
            'total_penalty_computations': len(self.computation_stats['penalty_computation_time']),
            'memory_usage': self.get_memory_usage(),
            'adaptive_importance': self.adaptive_importance,
            'forgetting_rates': self.forgetting_rates[-5:] if self.forgetting_rates else []
        }
        
        if self.computation_stats['fisher_magnitudes']:
            recent_mags = self.computation_stats['fisher_magnitudes'][-5:]
            stats['recent_fisher_magnitudes'] = {
                'avg': [m['avg'] for m in recent_mags],
                'max': [m['max'] for m in recent_mags]
            }
        
        return stats
    
    def save_ewc_data(self, save_path: str):
        """ä¿å­˜ EWC æ•¸æ“š"""
        ewc_data = {
            'fisher_matrices': self.fisher_matrices,
            'optimal_params': self.optimal_params,
            'task_count': self.task_count,
            'importance': self.importance,
            'adaptive_importance': self.adaptive_importance,
            'ewc_type': self.ewc_type,
            'computation_stats': self.computation_stats,
            'forgetting_rates': self.forgetting_rates,
            'importance_history': self.importance_history
        }
        
        if self.ewc_type == 'online':
            ewc_data.update({
                'consolidated_fisher': getattr(self, 'consolidated_fisher', {}),
                'consolidated_params': getattr(self, 'consolidated_params', {}),
                'gamma': getattr(self, 'gamma', 0.9)
            })
        
        torch.save(ewc_data, save_path)
        print(f"ğŸ’¾ EWC æ•¸æ“šå·²ä¿å­˜åˆ°: {save_path}")
    
    def load_ewc_data(self, load_path: str):
        """è¼‰å…¥ EWC æ•¸æ“š"""
        ewc_data = torch.load(load_path, map_location=self.device)
        
        self.fisher_matrices = ewc_data.get('fisher_matrices', {})
        self.optimal_params = ewc_data.get('optimal_params', {})
        self.task_count = ewc_data.get('task_count', 0)
        self.importance = ewc_data.get('importance', self.importance)
        self.adaptive_importance = ewc_data.get('adaptive_importance', self.importance)
        self.ewc_type = ewc_data.get('ewc_type', self.ewc_type)
        self.computation_stats = ewc_data.get('computation_stats', self.computation_stats)
        self.forgetting_rates = ewc_data.get('forgetting_rates', [])
        self.importance_history = ewc_data.get('importance_history', [self.importance])
        
        if self.ewc_type == 'online':
            self.consolidated_fisher = ewc_data.get('consolidated_fisher', {})
            self.consolidated_params = ewc_data.get('consolidated_params', {})
            self.gamma = ewc_data.get('gamma', 0.9)
        
        print(f"ğŸ“‚ EWC æ•¸æ“šå·²å¾ {load_path} è¼‰å…¥")


def ewc_loss(current_loss: torch.Tensor, 
            ewc_handler: EWC, 
            model: Optional[nn.Module] = None) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    è¨ˆç®—åŒ…å« EWC æ‡²ç½°é …çš„ç¸½æå¤±
    """
    ewc_penalty = ewc_handler.penalty(model)
    total_loss = current_loss + ewc_penalty
    
    return total_loss, ewc_penalty


def create_ewc_handler(model: nn.Module, 
                      importance: float = 5000.0,  # æé«˜é è¨­å€¼
                      ewc_type: str = 'l2',
                      **kwargs) -> EWC:
    """
    å‰µå»º EWC è™•ç†å™¨çš„å·¥å» å‡½æ•¸
    """
    return EWC(model=model, importance=importance, ewc_type=ewc_type, **kwargs)


if __name__ == "__main__":
    # æ¸¬è©¦ä¿®å¾©çš„EWC
    import torch.nn as nn
    
    # å‰µå»ºç°¡å–®æ¨¡å‹
    model = nn.Sequential(
        nn.Linear(10, 20),
        nn.ReLU(),
        nn.Linear(20, 5)
    )
    
    # å‰µå»º EWC è™•ç†å™¨
    ewc = create_ewc_handler(model, importance=5000.0)
    
    # å‰µå»ºè™›æ“¬æ•¸æ“š
    data = torch.randn(100, 10)
    labels = torch.randint(0, 5, (100,))
    dataset = torch.utils.data.TensorDataset(data, labels)
    dataloader = torch.utils.data.DataLoader(dataset, batch_size=10)
    
    # è¨ˆç®— Fisher çŸ©é™£
    fisher_matrix = ewc.compute_fisher_matrix(dataloader, verbose=True)
    
    # å­˜å„²æœ€å„ªåƒæ•¸
    ewc.store_optimal_params()
    
    # è¨ˆç®—æ‡²ç½°é …
    penalty = ewc.penalty()
    
    print(f"âœ… EWC æ¸¬è©¦å®Œæˆï¼")
    print(f"ğŸ“Š Fisher çŸ©é™£å±¤æ•¸: {len(fisher_matrix)}")
    print(f"ğŸ’° EWC æ‡²ç½°é …: {penalty.item():.6f}")
    print(f"ğŸ’¾ è¨˜æ†¶é«”ä½¿ç”¨: {ewc.get_memory_usage()}")
    print(f"ğŸ“ˆ è¨ˆç®—çµ±è¨ˆ: {ewc.get_computation_stats()}")