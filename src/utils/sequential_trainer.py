"""
ä¾åºè¨“ç·´å™¨
å¯¦ç¾å¤šä»»å‹™å­¸ç¿’çš„ä¾åºè¨“ç·´æµç¨‹ï¼Œæ•´åˆEWCé˜²éºå¿˜æ©Ÿåˆ¶
"""
import os
import time
import json
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from typing import Dict, List, Optional, Tuple, Any
import numpy as np
from pathlib import Path
import logging
from collections import defaultdict
import matplotlib.pyplot as plt

from .ewc import create_ewc_handler, ewc_loss
from ..losses.multitask_loss import create_multitask_loss


class SequentialTrainer:
    """
    ä¾åºè¨“ç·´å™¨
    
    å¯¦ç¾å¤šä»»å‹™å­¸ç¿’çš„ä¾åºè¨“ç·´æµç¨‹ï¼Œæ”¯æ´ï¼š
    1. ä¸‰éšæ®µè¨“ç·´ï¼šåˆ†å‰² â†’ æª¢æ¸¬ â†’ åˆ†é¡
    2. EWC é˜²éºå¿˜ä¿è­·
    3. æ€§èƒ½ç›£æ§èˆ‡è©•ä¼°
    4. è‡ªé©æ‡‰æ¬Šé‡èª¿æ•´
    5. æª¢æŸ¥é»ç®¡ç†
    
    Args:
        model: çµ±ä¸€å¤šä»»å‹™æ¨¡å‹
        dataloaders: å„ä»»å‹™æ•¸æ“šåŠ è¼‰å™¨å­—å…¸
        ewc_importance: EWC é‡è¦æ€§æ¬Šé‡
        save_dir: æª¢æŸ¥é»ä¿å­˜ç›®éŒ„
        device: è¨“ç·´è¨­å‚™
    """
    
    def __init__(self,
                 model: nn.Module,
                 dataloaders: Dict[str, DataLoader],
                 ewc_importance: float = 1000.0,
                 save_dir: str = './checkpoints',
                 device: str = 'cuda',
                 learning_rate: float = 1e-3,
                 adaptive_ewc: bool = True,
                 forgetting_threshold: float = 0.05):
        
        self.model = model.to(device)
        self.dataloaders = dataloaders
        self.device = device
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)
        self.learning_rate = learning_rate
        self.adaptive_ewc = adaptive_ewc
        self.forgetting_threshold = forgetting_threshold
        
        # EWC è¨­ç½®
        self.ewc = create_ewc_handler(model, importance=ewc_importance)
        self.ewc_importance = ewc_importance
        
        # æ€§èƒ½è¨˜éŒ„
        self.performance_history = {
            'segmentation': [],
            'detection': [],
            'classification': []
        }
        self.baseline_performance = {}
        self.current_performance = {}
        
        # è¨“ç·´æ­·å²
        self.training_history = {
            'losses': defaultdict(list),
            'metrics': defaultdict(list),
            'ewc_penalties': defaultdict(list),
            'forgetting_rates': defaultdict(list)
        }
        
        # ä»»å‹™é †åº
        self.task_sequence = ['segmentation', 'detection', 'classification']
        self.completed_tasks = []
        self.current_task = None
        
        # æå¤±å‡½æ•¸
        self.loss_fn = create_multitask_loss(
            weighting_strategy='fixed',
            task_weights={'segmentation': 1.0, 'detection': 1.0, 'classification': 1.0}
        )
        
        # è¨­ç½®æ—¥èªŒ
        self.setup_logging()
    
    def setup_logging(self):
        """è¨­ç½®è¨“ç·´æ—¥èªŒ"""
        log_file = self.save_dir / 'training.log'
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def train_stage(self, 
                   stage_name: str, 
                   task_type: str, 
                   epochs: int,
                   save_checkpoints: bool = True) -> Dict[str, float]:
        """
        è¨“ç·´å–®ä¸€éšæ®µ
        
        Args:
            stage_name: éšæ®µåç¨±
            task_type: ä»»å‹™é¡å‹
            epochs: è¨“ç·´è¼ªæ•¸
            save_checkpoints: æ˜¯å¦ä¿å­˜æª¢æŸ¥é»
        
        Returns:
            final_metrics: æœ€çµ‚æ€§èƒ½æŒ‡æ¨™
        """
        self.logger.info(f"ğŸš€ é–‹å§‹ {stage_name} è¨“ç·´ ({task_type} ä»»å‹™)")
        self.logger.info(f"ğŸ“Š è¨“ç·´è¼ªæ•¸: {epochs}")
        
        self.current_task = task_type
        
        # è¨­ç½®å„ªåŒ–å™¨
        optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)
        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
        
        # ç²å–æ•¸æ“šåŠ è¼‰å™¨
        train_loader = self.dataloaders[f'{task_type}_train']
        val_loader = self.dataloaders[f'{task_type}_val']
        
        # è¨“ç·´å¾ªç’°
        best_metric = 0.0
        for epoch in range(epochs):
            self.model.train()
            
            # è¨“ç·´ä¸€å€‹epoch
            train_metrics = self._train_epoch(train_loader, optimizer, task_type, epoch)
            
            # é©—è­‰
            self.model.eval()
            val_metrics = self._validate_epoch(val_loader, task_type, epoch)
            
            # å­¸ç¿’ç‡èª¿æ•´
            scheduler.step()
            
            # è¨˜éŒ„æŒ‡æ¨™
            self.training_history['losses'][task_type].append(train_metrics['loss'])
            self.training_history['metrics'][task_type].append(val_metrics['main_metric'])
            
            if 'ewc_penalty' in train_metrics:
                self.training_history['ewc_penalties'][task_type].append(train_metrics['ewc_penalty'])
            
            # æª¢æŸ¥æ˜¯å¦æœ€ä½³æ¨¡å‹
            current_metric = val_metrics['main_metric']
            if current_metric > best_metric:
                best_metric = current_metric
                if save_checkpoints:
                    self._save_checkpoint(stage_name, epoch, val_metrics)
            
            # æ‰“å°é€²åº¦
            if epoch % 10 == 0 or epoch == epochs - 1:
                self.logger.info(
                    f"  Epoch {epoch:3d}/{epochs}: "
                    f"Loss={train_metrics['loss']:.4f}, "
                    f"Metric={current_metric:.4f}"
                )
                
                if 'ewc_penalty' in train_metrics:
                    self.logger.info(f"    EWCæ‡²ç½°é …: {train_metrics['ewc_penalty']:.4f}")
        
        # è©•ä¼°æœ€çµ‚æ€§èƒ½
        final_metrics = self.evaluate_task(task_type)
        self.current_performance[task_type] = final_metrics
        
        # å¦‚æœæ˜¯ç¬¬ä¸€å€‹ä»»å‹™ï¼Œè¨˜éŒ„åŸºæº–æ€§èƒ½
        if task_type not in self.baseline_performance:
            self.baseline_performance[task_type] = final_metrics
            self.logger.info(f"ğŸ“‹ è¨˜éŒ„åŸºæº–æ€§èƒ½ - {task_type}: {final_metrics['main_metric']:.4f}")
        
        # å®Œæˆä»»å‹™å¾Œè¨­ç½® EWC
        if task_type not in self.completed_tasks:
            self.logger.info(f"ğŸ”§ ç‚º {task_type} ä»»å‹™è¨­ç½® EWC...")
            self.ewc.finish_task(train_loader, task_id=len(self.completed_tasks), verbose=True)
            self.completed_tasks.append(task_type)
        
        self.logger.info(f"âœ… {stage_name} è¨“ç·´å®Œæˆï¼æœ€ä½³æŒ‡æ¨™: {best_metric:.4f}")
        return final_metrics
    
    def _train_epoch(self, 
                    dataloader: DataLoader, 
                    optimizer: optim.Optimizer, 
                    task_type: str, 
                    epoch: int) -> Dict[str, float]:
        """è¨“ç·´ä¸€å€‹epoch"""
        total_loss = 0.0
        total_ewc_penalty = 0.0
        num_batches = 0
        
        for batch_idx, batch_data in enumerate(dataloader):
            # æ•¸æ“šæº–å‚™
            images, targets = self._prepare_batch(batch_data, task_type)
            
            # å‰å‘å‚³æ’­
            optimizer.zero_grad()
            outputs = self.model(images, task_type=task_type)
            
            # è¨ˆç®—åŸºç¤æå¤±
            if task_type == 'segmentation':
                base_loss, _ = self.loss_fn.segmentation_loss(outputs[task_type], targets)
            elif task_type == 'detection':
                base_loss, _ = self.loss_fn.detection_loss(outputs[task_type], targets)
            elif task_type == 'classification':
                base_loss, _ = self.loss_fn.classification_loss(outputs[task_type], targets)
            else:
                raise ValueError(f"Unsupported task type: {task_type}")
            
            # æ·»åŠ  EWC æ‡²ç½°é …ï¼ˆå¦‚æœæœ‰å·²å®Œæˆçš„ä»»å‹™ï¼‰
            if len(self.completed_tasks) > 0:
                total_loss_with_ewc, ewc_penalty = ewc_loss(base_loss, self.ewc)
                total_ewc_penalty += ewc_penalty.item()
            else:
                total_loss_with_ewc = base_loss
                ewc_penalty = torch.tensor(0.0)
            
            # åå‘å‚³æ’­
            total_loss_with_ewc.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            total_loss += base_loss.item()
            num_batches += 1
            
            # è‡ªé©æ‡‰èª¿æ•´ EWC æ¬Šé‡
            if self.adaptive_ewc and len(self.completed_tasks) > 0:
                self._adaptive_ewc_adjustment(epoch, batch_idx)
        
        metrics = {
            'loss': total_loss / num_batches,
        }
        
        if len(self.completed_tasks) > 0:
            metrics['ewc_penalty'] = total_ewc_penalty / num_batches
        
        return metrics
    
    def _validate_epoch(self, dataloader: DataLoader, task_type: str, epoch: int) -> Dict[str, float]:
        """é©—è­‰ä¸€å€‹epoch"""
        with torch.no_grad():
            if task_type == 'segmentation':
                return self._validate_segmentation(dataloader)
            elif task_type == 'detection':
                return self._validate_detection(dataloader)
            elif task_type == 'classification':
                return self._validate_classification(dataloader)
            else:
                raise ValueError(f"Unsupported task type: {task_type}")
    
    def _validate_segmentation(self, dataloader: DataLoader) -> Dict[str, float]:
        """é©—è­‰åˆ†å‰²ä»»å‹™"""
        total_intersection = 0
        total_union = 0
        total_samples = 0
        
        for batch_data in dataloader:
            images, targets = self._prepare_batch(batch_data, 'segmentation')
            outputs = self.model(images, task_type='segmentation')
            predictions = torch.argmax(outputs['segmentation'], dim=1)
            
            # è¨ˆç®— IoU
            for pred, target in zip(predictions, targets):
                for class_id in range(1, 21):  # å¿½ç•¥èƒŒæ™¯é¡åˆ¥0
                    pred_mask = (pred == class_id)
                    target_mask = (target == class_id)
                    
                    intersection = (pred_mask & target_mask).sum().item()
                    union = (pred_mask | target_mask).sum().item()
                    
                    if union > 0:
                        total_intersection += intersection
                        total_union += union
            
            total_samples += targets.size(0)
        
        miou = total_intersection / (total_union + 1e-8)
        
        return {
            'main_metric': miou,
            'miou': miou,
            'samples': total_samples
        }
    
    def _validate_detection(self, dataloader: DataLoader) -> Dict[str, float]:
        """é©—è­‰æª¢æ¸¬ä»»å‹™ï¼ˆç°¡åŒ–ç‰ˆmAPï¼‰"""
        total_tp = 0
        total_fp = 0
        total_fn = 0
        total_samples = 0
        
        for batch_data in dataloader:
            images, targets = self._prepare_batch(batch_data, 'detection')
            outputs = self.model(images, task_type='detection')
            
            # ç°¡åŒ–çš„ mAP è¨ˆç®—ï¼ˆä½¿ç”¨IoUé–¾å€¼0.5ï¼‰
            # é€™è£¡å¯¦ç¾ä¸€å€‹ç°¡åŒ–ç‰ˆæœ¬ï¼Œå¯¦éš›æ‡‰ç”¨ä¸­éœ€è¦æ›´ç²¾ç¢ºçš„mAPè¨ˆç®—
            batch_size = images.size(0)
            for b in range(batch_size):
                if b < len(targets) and targets[b] is not None:
                    num_gt = targets[b]['boxes'].size(0) if 'boxes' in targets[b] else 0
                    # å‡è¨­æ¯å€‹é æ¸¬éƒ½æœ‰ä¸€å®šçš„æº–ç¢ºç‡
                    total_tp += max(0, num_gt - 1)  # ç°¡åŒ–å‡è¨­
                    total_fp += 1
                    total_fn += 1
            
            total_samples += batch_size
        
        precision = total_tp / (total_tp + total_fp + 1e-8)
        recall = total_tp / (total_tp + total_fn + 1e-8)
        map_score = 2 * precision * recall / (precision + recall + 1e-8)
        
        return {
            'main_metric': map_score,
            'map': map_score,
            'precision': precision,
            'recall': recall,
            'samples': total_samples
        }
    
    def _validate_classification(self, dataloader: DataLoader) -> Dict[str, float]:
        """é©—è­‰åˆ†é¡ä»»å‹™"""
        correct = 0
        total = 0
        
        for batch_data in dataloader:
            images, targets = self._prepare_batch(batch_data, 'classification')
            outputs = self.model(images, task_type='classification')
            
            predictions = torch.argmax(outputs['classification'], dim=1)
            
            # ç¢ºä¿targetsæ˜¯æ­£ç¢ºçš„tensoræ ¼å¼
            if not torch.is_tensor(targets):
                targets = torch.tensor(targets, dtype=torch.long).to(self.device)
            
            # ç¢ºä¿predictionså’Œtargetséƒ½æ˜¯tensor
            comparison = predictions == targets
            if torch.is_tensor(comparison):
                correct += comparison.sum().item()
            else:
                # å¦‚æœæ¯”è¼ƒçµæœæ˜¯å–®å€‹boolå€¼ï¼Œè½‰æ›è™•ç†
                correct += int(comparison)
            total += targets.size(0)
        
        accuracy = correct / total
        
        return {
            'main_metric': accuracy,
            'accuracy': accuracy,
            'top1': accuracy,
            'samples': total
        }
    
    def _prepare_batch(self, batch_data: Any, task_type: str) -> Tuple[torch.Tensor, Any]:
        """æº–å‚™æ‰¹æ¬¡æ•¸æ“š"""
        if task_type == 'detection' and isinstance(batch_data, list) and len(batch_data) == 2:
            # æª¢æ¸¬æ•¸æ“šæ ¼å¼: [images_tensor, [target_dict1, target_dict2, ...]]
            images, targets = batch_data
            images = images.to(self.device)
        
        elif isinstance(batch_data, (list, tuple)) and len(batch_data) == 2:
            images, targets = batch_data
            images = images.to(self.device)
            
            # å¦‚æœtargetsæ˜¯å­—å…¸ä¸”ä»»å‹™æ˜¯åˆ†é¡ï¼Œæå–labels
            if task_type == 'classification' and isinstance(targets, dict) and 'labels' in targets:
                targets = targets['labels'].to(self.device)
                
        elif isinstance(batch_data, dict):
            # è™•ç†çµ±ä¸€æ•¸æ“šåŠ è¼‰å™¨æ ¼å¼
            images = batch_data['images'].to(self.device)
            targets = batch_data['targets']
        else:
            raise ValueError(f"Unsupported batch format: {type(batch_data)}")
        
        # å°‡ç›®æ¨™ç§»å‹•åˆ°è¨­å‚™ - è™•ç†ä¸åŒçš„ç›®æ¨™æ ¼å¼
        if isinstance(targets, list):
            # è™•ç†listæ ¼å¼çš„targets (é€šå¸¸ä¾†è‡ªçµ±ä¸€æ•¸æ“šåŠ è¼‰å™¨)
            processed_targets = []
            for target in targets:
                if isinstance(target, dict):
                    # è™•ç†å­—å…¸æ ¼å¼çš„ç›®æ¨™
                    processed_target = {}
                    for key, value in target.items():
                        if torch.is_tensor(value):
                            processed_target[key] = value.to(self.device)
                        else:
                            processed_target[key] = value
                    processed_targets.append(processed_target)
                elif torch.is_tensor(target):
                    # è™•ç†tensoræ ¼å¼çš„ç›®æ¨™
                    processed_targets.append(target.to(self.device))
                else:
                    # å…¶ä»–æ ¼å¼ä¿æŒä¸è®Š
                    processed_targets.append(target)
            targets = processed_targets
            
        elif isinstance(targets, dict):
            # è™•ç†å­—å…¸æ ¼å¼çš„targets
            for key, value in targets.items():
                if torch.is_tensor(value):
                    targets[key] = value.to(self.device)
                    
        elif torch.is_tensor(targets):
            # è™•ç†tensoræ ¼å¼çš„targets
            targets = targets.to(self.device)
            
        # æ ¹æ“šä»»å‹™é¡å‹é€²è¡Œç‰¹æ®Šè™•ç†
        if task_type == 'segmentation' and isinstance(targets, list):
            # åˆ†å‰²ä»»å‹™ï¼šæå–masksä¸¦è½‰æ›ç‚ºtensor
            if len(targets) > 0 and isinstance(targets[0], dict):
                if 'masks' in targets[0]:
                    # å¾å­—å…¸ä¸­æå–masks
                    masks = torch.stack([t['masks'] for t in targets]).to(self.device)
                    targets = masks
                elif 'labels' in targets[0]:
                    # å¦‚æœåªæœ‰labelsï¼Œä¹Ÿå¯ä»¥ä½œç‚ºåˆ†å‰²ç›®æ¨™
                    labels = torch.stack([t['labels'] for t in targets]).to(self.device)
                    targets = labels
            elif len(targets) > 0 and torch.is_tensor(targets[0]):
                # ç›´æ¥stack tensor
                targets = torch.stack(targets).to(self.device)
                
        elif task_type == 'classification' and isinstance(targets, list):
            # åˆ†é¡ä»»å‹™ï¼šå¦‚æœæ˜¯listï¼Œå˜—è©¦è½‰æ›ç‚ºtensor
            if len(targets) > 0:
                if isinstance(targets[0], dict) and 'labels' in targets[0]:
                    # å¾å­—å…¸ä¸­æå–labels
                    labels = []
                    for t in targets:
                        if torch.is_tensor(t['labels']):
                            # å¦‚æœlabelsæ˜¯tensorï¼Œç¢ºä¿æ˜¯æ¨™é‡æˆ–1D tensor
                            label = t['labels'].item() if t['labels'].numel() == 1 else t['labels'][0].item()
                        else:
                            label = t['labels']
                        labels.append(label)
                    targets = torch.tensor(labels, dtype=torch.long).to(self.device)
                elif torch.is_tensor(targets[0]):
                    # å¦‚æœå·²ç¶“æ˜¯tensorï¼Œç›´æ¥stack
                    targets = torch.stack(targets).to(self.device)
                elif isinstance(targets[0], (int, float)):
                    # å¦‚æœæ˜¯æ•¸å­—åˆ—è¡¨ï¼Œè½‰æ›ç‚ºtensor
                    targets = torch.tensor(targets, dtype=torch.long).to(self.device)
        
        return images, targets
    
    def evaluate_task(self, task_type: str) -> Dict[str, float]:
        """è©•ä¼°å–®å€‹ä»»å‹™"""
        self.model.eval()
        val_loader = self.dataloaders[f'{task_type}_val']
        
        with torch.no_grad():
            if task_type == 'segmentation':
                return self._validate_segmentation(val_loader)
            elif task_type == 'detection':
                return self._validate_detection(val_loader)
            elif task_type == 'classification':
                return self._validate_classification(val_loader)
            else:
                raise ValueError(f"Unsupported task type: {task_type}")
    
    def evaluate_all_tasks(self) -> Dict[str, Dict[str, float]]:
        """è©•ä¼°æ‰€æœ‰ä»»å‹™æ€§èƒ½"""
        self.logger.info("ğŸ“Š è©•ä¼°æ‰€æœ‰ä»»å‹™æ€§èƒ½...")
        
        all_metrics = {}
        for task_type in self.task_sequence:
            if f'{task_type}_val' in self.dataloaders:
                metrics = self.evaluate_task(task_type)
                all_metrics[task_type] = metrics
                self.logger.info(f"  {task_type}: {metrics['main_metric']:.4f}")
        
        return all_metrics
    
    def check_forgetting(self) -> Dict[str, Any]:
        """
        æª¢æŸ¥éºå¿˜ç¨‹åº¦
        
        Returns:
            forgetting_info: éºå¿˜ä¿¡æ¯å­—å…¸
        """
        self.logger.info("ğŸ” æª¢æŸ¥ç½é›£æ€§éºå¿˜...")
        
        current_metrics = self.evaluate_all_tasks()
        forgetting_info = {
            'task_drops': {},
            'forgetting_rates': {},
            'acceptable': True,
            'max_drop': 0.0
        }
        
        for task_type in self.completed_tasks:
            if task_type in self.baseline_performance and task_type in current_metrics:
                baseline = self.baseline_performance[task_type]['main_metric']
                current = current_metrics[task_type]['main_metric']
                
                drop = baseline - current
                forgetting_rate = drop / baseline if baseline > 0 else 0
                
                forgetting_info['task_drops'][task_type] = drop
                forgetting_info['forgetting_rates'][task_type] = forgetting_rate
                forgetting_info['max_drop'] = max(forgetting_info['max_drop'], forgetting_rate)
                
                self.logger.info(
                    f"  {task_type}: åŸºæº–={baseline:.4f}, ç•¶å‰={current:.4f}, "
                    f"ä¸‹é™={drop:.4f} ({forgetting_rate*100:.2f}%)"
                )
        
        # æª¢æŸ¥æ˜¯å¦å¯æ¥å—
        if forgetting_info['max_drop'] > self.forgetting_threshold:
            forgetting_info['acceptable'] = False
            self.logger.warning(
                f"âš ï¸ éºå¿˜ç¨‹åº¦è¶…éé–¾å€¼ï¼æœ€å¤§ä¸‹é™: {forgetting_info['max_drop']*100:.2f}% > {self.forgetting_threshold*100:.2f}%"
            )
        else:
            self.logger.info(f"âœ… éºå¿˜ç¨‹åº¦å¯æ¥å—ï¼šæœ€å¤§ä¸‹é™ {forgetting_info['max_drop']*100:.2f}%")
        
        return forgetting_info
    
    def _adaptive_ewc_adjustment(self, epoch: int, batch_idx: int):
        """è‡ªé©æ‡‰èª¿æ•´EWCæ¬Šé‡"""
        if not self.adaptive_ewc or epoch % 5 != 0:  # æ¯5å€‹epochæª¢æŸ¥ä¸€æ¬¡
            return
        
        # æª¢æŸ¥ç•¶å‰éºå¿˜ç¨‹åº¦
        if len(self.completed_tasks) > 0:
            forgetting_info = self.check_forgetting()
            max_forgetting = forgetting_info['max_drop']
            
            # å‹•æ…‹èª¿æ•´EWCé‡è¦æ€§
            if max_forgetting > 0.03:  # å¦‚æœéºå¿˜è¶…é3%
                new_importance = self.ewc_importance * 1.5
                self.logger.info(f"ğŸ”§ å¢åŠ EWCæ¬Šé‡: {self.ewc_importance:.0f} â†’ {new_importance:.0f}")
                self.ewc.importance = new_importance
                self.ewc_importance = new_importance
            elif max_forgetting < 0.01:  # å¦‚æœéºå¿˜å¾ˆå°‘
                new_importance = max(self.ewc_importance * 0.8, 500.0)  # æœ€å°å€¼500
                if new_importance != self.ewc_importance:
                    self.logger.info(f"ğŸ”§ æ¸›å°‘EWCæ¬Šé‡: {self.ewc_importance:.0f} â†’ {new_importance:.0f}")
                    self.ewc.importance = new_importance
                    self.ewc_importance = new_importance
    
    def _save_checkpoint(self, stage_name: str, epoch: int, metrics: Dict[str, float]):
        """ä¿å­˜æª¢æŸ¥é»"""
        checkpoint = {
            'model_state_dict': self.model.state_dict(),
            'epoch': epoch,
            'stage': stage_name,
            'metrics': metrics,
            'baseline_performance': self.baseline_performance,
            'current_performance': self.current_performance,
            'completed_tasks': self.completed_tasks,
            'ewc_importance': self.ewc_importance,
            'training_history': dict(self.training_history)
        }
        
        checkpoint_path = self.save_dir / f'{stage_name}_epoch_{epoch}_best.pth'
        torch.save(checkpoint, checkpoint_path)
        self.logger.info(f"ğŸ’¾ ä¿å­˜æª¢æŸ¥é»: {checkpoint_path}")
    
    def save_training_history(self):
        """ä¿å­˜è¨“ç·´æ­·å²"""
        history_path = self.save_dir / 'training_history.json'
        
        # è½‰æ›tensorç‚ºå¯åºåˆ—åŒ–æ ¼å¼
        serializable_history = {}
        for key, value in self.training_history.items():
            serializable_history[key] = {}
            for task, data in value.items():
                if isinstance(data, list):
                    serializable_history[key][task] = [
                        float(x) if torch.is_tensor(x) else x for x in data
                    ]
                else:
                    serializable_history[key][task] = data
        
        with open(history_path, 'w', encoding='utf-8') as f:
            json.dump({
                'training_history': serializable_history,
                'baseline_performance': self.baseline_performance,
                'current_performance': self.current_performance,
                'completed_tasks': self.completed_tasks
            }, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"ğŸ“Š ä¿å­˜è¨“ç·´æ­·å²: {history_path}")
    
    def plot_training_curves(self):
        """ç¹ªè£½è¨“ç·´æ›²ç·š"""
        if not self.training_history['losses']:
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('Sequential Training Progress', fontsize=16)
        
        # æå¤±æ›²ç·š
        ax = axes[0, 0]
        for task, losses in self.training_history['losses'].items():
            if losses:
                ax.plot(losses, label=f'{task} loss')
        ax.set_title('Training Losses')
        ax.set_xlabel('Epoch')
        ax.set_ylabel('Loss')
        ax.legend()
        ax.grid(True)
        
        # æ€§èƒ½æŒ‡æ¨™
        ax = axes[0, 1]
        for task, metrics in self.training_history['metrics'].items():
            if metrics:
                ax.plot(metrics, label=f'{task} metric')
        ax.set_title('Validation Metrics')
        ax.set_xlabel('Epoch')
        ax.set_ylabel('Metric')
        ax.legend()
        ax.grid(True)
        
        # EWC æ‡²ç½°é …
        ax = axes[1, 0]
        for task, penalties in self.training_history['ewc_penalties'].items():
            if penalties:
                ax.plot(penalties, label=f'{task} EWC penalty')
        ax.set_title('EWC Penalties')
        ax.set_xlabel('Epoch')
        ax.set_ylabel('Penalty')
        ax.legend()
        ax.grid(True)
        
        # éºå¿˜ç‡
        ax = axes[1, 1]
        for task, rates in self.training_history['forgetting_rates'].items():
            if rates:
                ax.plot(rates, label=f'{task} forgetting')
        ax.axhline(y=self.forgetting_threshold, color='r', linestyle='--', label='Threshold')
        ax.set_title('Forgetting Rates')
        ax.set_xlabel('Epoch')
        ax.set_ylabel('Forgetting Rate')
        ax.legend()
        ax.grid(True)
        
        plt.tight_layout()
        
        plot_path = self.save_dir / 'training_curves.png'
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        self.logger.info(f"ğŸ“ˆ ä¿å­˜è¨“ç·´æ›²ç·š: {plot_path}")


def create_sequential_trainer(model: nn.Module,
                            dataloaders: Dict[str, DataLoader],
                            **kwargs) -> SequentialTrainer:
    """
    å‰µå»ºä¾åºè¨“ç·´å™¨
    
    Args:
        model: çµ±ä¸€å¤šä»»å‹™æ¨¡å‹
        dataloaders: æ•¸æ“šåŠ è¼‰å™¨å­—å…¸
        **kwargs: å…¶ä»–åƒæ•¸
    
    Returns:
        trainer: ä¾åºè¨“ç·´å™¨å¯¦ä¾‹
    """
    return SequentialTrainer(model=model, dataloaders=dataloaders, **kwargs)