import numpy as np
import torch
import json
from typing import Dict, List, Tuple, Optional
from itertools import product
import os
from datetime import datetime

class HyperparameterOptimizer:
    """è¶…åƒæ•¸å„ªåŒ–å™¨ï¼Œå°ˆæ³¨æ–¼é™ä½ç½é›£æ€§éºå¿˜ç‡"""
    
    def __init__(self):
        # åŸºæ–¼ç½é›£æ€§éºå¿˜è©•ä¼°èª¿æ•´åƒæ•¸ç©ºé–“
        self.param_space = {
            'learning_rate': {
                'classification': [1e-3, 2e-3, 5e-3, 1e-2],  # é‡é»æå‡åˆ†é¡å­¸ç¿’ç‡
                'segmentation': [5e-4, 1e-3, 2e-3],          # åˆ†å‰²å¾®èª¿
                'detection': [1e-4, 5e-4, 1e-3]              # æª¢æ¸¬ä¿æŒç©©å®š
            },
            'task_weights': {
                'classification': [3.0, 5.0, 8.0, 10.0],     # å¤§å¹…æé«˜åˆ†é¡æ¬Šé‡
                'segmentation': [1.5, 2.0, 2.5],             # åˆ†å‰²é©åº¦èª¿æ•´
                'detection': [0.3, 0.5, 0.8]                 # æª¢æ¸¬é™ä½é¿å…éåº¦ä¸»å°
            },
            'architecture_changes': {
                'remove_classification_batchnorm': True,      # ç§»é™¤åˆ†é¡BatchNorm
                'classification_head_layers': [2, 3, 4],      # èª¿æ•´åˆ†é¡é ­éƒ¨æ·±åº¦
                'dropout_rate': [0.1, 0.3, 0.5]              # æ­£å‰‡åŒ–ç­–ç•¥
            },
            'training_params': {
                'epochs': [30, 50, 100],                      # è¨“ç·´è¼ªæ•¸
                'batch_size': [8, 16, 32],                    # æ‰¹æ¬¡å¤§å°
                'gradient_clip': [0.5, 1.0, 2.0],            # æ¢¯åº¦è£å‰ª
                'label_smoothing': [0.0, 0.1, 0.2]          # æ¨™ç±¤å¹³æ»‘
            }
        }
        
        self.results_history = []
        self.best_config = None
        self.best_forgetting_rates = {
            'classification': float('inf'),
            'segmentation': float('inf'),
            'detection': float('inf')
        }
        
    def grid_search(self, model_builder, train_func, eval_func, max_trials=10):
        """
        åŸ·è¡Œç¶²æ ¼æœç´¢ï¼Œå°‹æ‰¾æœ€ä½³è¶…åƒæ•¸çµ„åˆ
        
        Args:
            model_builder: æ§‹å»ºæ¨¡å‹çš„å‡½æ•¸
            train_func: è¨“ç·´å‡½æ•¸
            eval_func: è©•ä¼°å‡½æ•¸ï¼ˆè¿”å›éºå¿˜ç‡ï¼‰
            max_trials: æœ€å¤§è©¦é©—æ¬¡æ•¸
        """
        # ç”Ÿæˆåƒæ•¸çµ„åˆ
        param_combinations = self._generate_combinations()
        
        # æ ¹æ“šå„ªå…ˆç´šæ’åºï¼ˆå„ªå…ˆæ¸¬è©¦é«˜åˆ†é¡å­¸ç¿’ç‡å’Œæ¬Šé‡çš„çµ„åˆï¼‰
        param_combinations = self._prioritize_combinations(param_combinations)
        
        # é™åˆ¶è©¦é©—æ¬¡æ•¸
        param_combinations = param_combinations[:max_trials]
        
        print(f"ğŸ” é–‹å§‹è¶…åƒæ•¸æœç´¢ï¼Œå…± {len(param_combinations)} å€‹çµ„åˆ")
        
        for idx, params in enumerate(param_combinations):
            print(f"\nğŸ“Š è©¦é©— {idx+1}/{len(param_combinations)}")
            print(f"åƒæ•¸é…ç½®: {json.dumps(params, indent=2)}")
            
            # æ§‹å»ºæ¨¡å‹
            model = model_builder(params['architecture_changes'])
            
            # è¨“ç·´æ¨¡å‹
            trained_model = train_func(
                model,
                learning_rates=params['learning_rate'],
                task_weights=params['task_weights'],
                **params['training_params']
            )
            
            # è©•ä¼°éºå¿˜ç‡
            forgetting_rates = eval_func(trained_model)
            
            # è¨˜éŒ„çµæœ
            result = {
                'params': params,
                'forgetting_rates': forgetting_rates,
                'timestamp': datetime.now().isoformat()
            }
            self.results_history.append(result)
            
            # æ›´æ–°æœ€ä½³é…ç½®
            if self._is_better(forgetting_rates):
                self.best_config = params
                self.best_forgetting_rates = forgetting_rates.copy()
                print(f"âœ… æ–°çš„æœ€ä½³é…ç½®ï¼éºå¿˜ç‡: {forgetting_rates}")
                
            # æ—©åœæ¢ä»¶ï¼šæ‰€æœ‰ä»»å‹™éºå¿˜ç‡éƒ½ â‰¤5%
            if all(rate <= 5.0 for rate in forgetting_rates.values()):
                print(f"ğŸ¯ é”åˆ°ç›®æ¨™ï¼æ‰€æœ‰ä»»å‹™éºå¿˜ç‡ â‰¤5%")
                break
                
        return self.best_config, self.best_forgetting_rates
    
    def suggest_improvements(self, current_results: Dict[str, float]) -> Dict[str, any]:
        """
        åŸºæ–¼ç•¶å‰çµæœå»ºè­°æ”¹é€²æ–¹å‘
        
        Args:
            current_results: ç•¶å‰çš„éºå¿˜ç‡çµæœ
            
        Returns:
            æ”¹é€²å»ºè­°å­—å…¸
        """
        suggestions = {
            'priority_tasks': [],
            'parameter_adjustments': {},
            'architecture_changes': {},
            'training_strategy': []
        }
        
        # åˆ†æå„ä»»å‹™çš„éºå¿˜ç‡
        for task, rate in current_results.items():
            if rate > 5.0:
                suggestions['priority_tasks'].append(task)
                
                if task == 'classification' and rate > 20:
                    # åˆ†é¡ä»»å‹™åš´é‡éºå¿˜
                    suggestions['parameter_adjustments'][task] = {
                        'learning_rate': 'increase_by_5x',
                        'task_weight': 'increase_to_8-10x',
                        'reason': 'åˆ†é¡ä»»å‹™æ¢¯åº¦è¢«åš´é‡å£“åˆ¶'
                    }
                    suggestions['architecture_changes'][task] = {
                        'remove_batchnorm': True,
                        'increase_capacity': True,
                        'add_skip_connections': True
                    }
                    
                elif task == 'segmentation' and rate > 5:
                    # åˆ†å‰²ä»»å‹™è¼•å¾®éºå¿˜
                    suggestions['parameter_adjustments'][task] = {
                        'learning_rate': 'increase_by_1.5x',
                        'task_weight': 'increase_to_2x',
                        'reason': 'åˆ†å‰²ä»»å‹™éœ€è¦å¾®èª¿'
                    }
                    
        # è¨“ç·´ç­–ç•¥å»ºè­°
        if len(suggestions['priority_tasks']) > 0:
            suggestions['training_strategy'].extend([
                'è€ƒæ…®ä½¿ç”¨ä»»å‹™ç‰¹å®šçš„å­¸ç¿’ç‡èª¿åº¦',
                'å¢åŠ é«˜å„ªå…ˆç´šä»»å‹™çš„æ‰¹æ¬¡æ¡æ¨£é »ç‡',
                'ä½¿ç”¨æ¢¯åº¦ç´¯ç©ä¾†ç©©å®šè¨“ç·´',
                'è€ƒæ…®é ç†±æœŸå–®ç¨è¨“ç·´å•é¡Œä»»å‹™'
            ])
            
        return suggestions
    
    def _generate_combinations(self) -> List[Dict]:
        """ç”Ÿæˆæ‰€æœ‰åƒæ•¸çµ„åˆ"""
        combinations = []
        
        # æå–å„é¡åƒæ•¸
        lr_combos = list(product(
            self.param_space['learning_rate']['classification'],
            self.param_space['learning_rate']['segmentation'],
            self.param_space['learning_rate']['detection']
        ))
        
        weight_combos = list(product(
            self.param_space['task_weights']['classification'],
            self.param_space['task_weights']['segmentation'],
            self.param_space['task_weights']['detection']
        ))
        
        arch_combos = list(product(
            self.param_space['architecture_changes']['classification_head_layers'],
            self.param_space['architecture_changes']['dropout_rate']
        ))
        
        train_combos = list(product(
            self.param_space['training_params']['epochs'],
            self.param_space['training_params']['batch_size'],
            self.param_space['training_params']['gradient_clip'],
            self.param_space['training_params']['label_smoothing']
        ))
        
        # çµ„åˆæ‰€æœ‰åƒæ•¸
        for lr, weight, arch, train in product(lr_combos, weight_combos, arch_combos, train_combos):
            combo = {
                'learning_rate': {
                    'classification': lr[0],
                    'segmentation': lr[1],
                    'detection': lr[2]
                },
                'task_weights': {
                    'classification': weight[0],
                    'segmentation': weight[1],
                    'detection': weight[2]
                },
                'architecture_changes': {
                    'remove_classification_batchnorm': self.param_space['architecture_changes']['remove_classification_batchnorm'],
                    'classification_head_layers': arch[0],
                    'dropout_rate': arch[1]
                },
                'training_params': {
                    'epochs': train[0],
                    'batch_size': train[1],
                    'gradient_clip': train[2],
                    'label_smoothing': train[3]
                }
            }
            combinations.append(combo)
            
        return combinations
    
    def _prioritize_combinations(self, combinations: List[Dict]) -> List[Dict]:
        """æ ¹æ“šå„ªå…ˆç´šæ’åºåƒæ•¸çµ„åˆ"""
        def priority_score(combo):
            # å„ªå…ˆè€ƒæ…®é«˜åˆ†é¡å­¸ç¿’ç‡å’Œæ¬Šé‡çš„çµ„åˆ
            score = 0
            score += combo['learning_rate']['classification'] * 1000
            score += combo['task_weights']['classification'] * 100
            score += (50 - combo['training_params']['epochs']) * 0.1  # å„ªå…ˆçŸ­è¨“ç·´
            return score
            
        return sorted(combinations, key=priority_score, reverse=True)
    
    def _is_better(self, new_rates: Dict[str, float]) -> bool:
        """åˆ¤æ–·æ–°çš„éºå¿˜ç‡æ˜¯å¦æ›´å¥½"""
        # å„ªå…ˆç´šï¼šé¦–å…ˆç¢ºä¿æ‰€æœ‰ä»»å‹™ â‰¤5%ï¼Œç„¶å¾Œæœ€å°åŒ–ç¸½éºå¿˜ç‡
        current_violations = sum(1 for rate in self.best_forgetting_rates.values() if rate > 5.0)
        new_violations = sum(1 for rate in new_rates.values() if rate > 5.0)
        
        if new_violations < current_violations:
            return True
        elif new_violations == current_violations:
            return sum(new_rates.values()) < sum(self.best_forgetting_rates.values())
        return False
    
    def save_results(self, filepath: str):
        """ä¿å­˜å„ªåŒ–çµæœ"""
        results = {
            'best_config': self.best_config,
            'best_forgetting_rates': self.best_forgetting_rates,
            'all_results': self.results_history,
            'timestamp': datetime.now().isoformat()
        }
        
        with open(filepath, 'w') as f:
            json.dump(results, f, indent=2)
            
        print(f"ğŸ’¾ å„ªåŒ–çµæœå·²ä¿å­˜è‡³: {filepath}")


class AdaptiveLossWeighting:
    """è‡ªé©æ‡‰æå¤±æ¬Šé‡èª¿æ•´ï¼Œå°ˆæ³¨æ–¼é™ä½éºå¿˜ç‡"""
    
    def __init__(self):
        self.weights_history = []
        self.performance_history = []
        # åŸºæ–¼ç½é›£æ€§éºå¿˜ç›®æ¨™è¨­å®šæ¬Šé‡
        self.target_forgetting_rates = {
            'classification': 5.0,  # æœ€å¤§å…è¨±éºå¿˜ç‡
            'segmentation': 5.0,
            'detection': 5.0
        }
        
        # åˆå§‹æ¬Šé‡ï¼ˆåŸºæ–¼è¨ºæ–·çµæœï¼‰
        self.current_weights = {
            'classification': 5.0,  # é«˜æ¬Šé‡å¹«åŠ©åˆ†é¡å­¸ç¿’
            'segmentation': 2.0,    # é©ä¸­æ¬Šé‡
            'detection': 0.5        # ä½æ¬Šé‡é¿å…éåº¦ä¸»å°
        }
        
        # æ¬Šé‡èª¿æ•´åƒæ•¸
        self.adjustment_rate = 0.1
        self.min_weights = {'classification': 1.0, 'segmentation': 0.5, 'detection': 0.1}
        self.max_weights = {'classification': 10.0, 'segmentation': 5.0, 'detection': 2.0}
        
    def update_weights(self, current_losses: Dict[str, float], 
                      current_forgetting_rates: Dict[str, float]) -> Dict[str, float]:
        """
        åŸºæ–¼ç•¶å‰æå¤±å’Œéºå¿˜ç‡æ›´æ–°æ¬Šé‡
        
        Args:
            current_losses: ç•¶å‰å„ä»»å‹™çš„æå¤±å€¼
            current_forgetting_rates: ç•¶å‰å„ä»»å‹™çš„éºå¿˜ç‡
            
        Returns:
            æ›´æ–°å¾Œçš„æ¬Šé‡
        """
        # è¨˜éŒ„æ­·å²
        self.weights_history.append(self.current_weights.copy())
        self.performance_history.append({
            'losses': current_losses.copy(),
            'forgetting_rates': current_forgetting_rates.copy()
        })
        
        # è¨ˆç®—æ¬Šé‡èª¿æ•´
        for task in self.current_weights:
            if task in current_forgetting_rates:
                forgetting_rate = current_forgetting_rates[task]
                target_rate = self.target_forgetting_rates[task]
                
                # å¦‚æœéºå¿˜ç‡è¶…éç›®æ¨™ï¼Œå¢åŠ æ¬Šé‡
                if forgetting_rate > target_rate:
                    # èª¿æ•´å¹…åº¦èˆ‡è¶…å‡ºç¨‹åº¦æˆæ­£æ¯”
                    adjustment = self.adjustment_rate * (forgetting_rate - target_rate) / target_rate
                    self.current_weights[task] *= (1 + adjustment)
                    
                # å¦‚æœéºå¿˜ç‡é ä½æ–¼ç›®æ¨™ï¼Œå¯ä»¥é©åº¦é™ä½æ¬Šé‡
                elif forgetting_rate < target_rate * 0.5:
                    adjustment = self.adjustment_rate * 0.5
                    self.current_weights[task] *= (1 - adjustment)
                    
                # é™åˆ¶æ¬Šé‡ç¯„åœ
                self.current_weights[task] = np.clip(
                    self.current_weights[task],
                    self.min_weights[task],
                    self.max_weights[task]
                )
                
        # æ­¸ä¸€åŒ–æ¬Šé‡ï¼ˆå¯é¸ï¼‰
        # total = sum(self.current_weights.values())
        # self.current_weights = {k: v/total * 3.0 for k, v in self.current_weights.items()}
        
        return self.current_weights
    
    def suggest_optimal_weights(self) -> Dict[str, float]:
        """åŸºæ–¼æ­·å²æ•¸æ“šå»ºè­°æœ€ä½³æ¬Šé‡çµ„åˆ"""
        if len(self.performance_history) < 5:
            # æ•¸æ“šä¸è¶³ï¼Œè¿”å›ç•¶å‰æ¬Šé‡
            return self.current_weights
            
        # æ‰¾å‡ºéºå¿˜ç‡æœ€ä½çš„é…ç½®
        best_idx = -1
        best_total_forgetting = float('inf')
        
        for i, perf in enumerate(self.performance_history):
            total_forgetting = sum(perf['forgetting_rates'].values())
            violations = sum(1 for rate in perf['forgetting_rates'].values() if rate > 5.0)
            
            # å„ªå…ˆé¸æ“‡ç„¡é•è¦çš„é…ç½®
            if violations == 0 and total_forgetting < best_total_forgetting:
                best_total_forgetting = total_forgetting
                best_idx = i
            elif best_idx == -1 and total_forgetting < best_total_forgetting:
                best_total_forgetting = total_forgetting
                best_idx = i
                
        if best_idx >= 0:
            return self.weights_history[best_idx]
        return self.current_weights
    
    def get_weight_analysis(self) -> Dict:
        """åˆ†ææ¬Šé‡è®ŠåŒ–è¶¨å‹¢"""
        if len(self.weights_history) < 2:
            return {'status': 'æ•¸æ“šä¸è¶³', 'trend': {}}
            
        analysis = {
            'current_weights': self.current_weights,
            'weight_trends': {},
            'recommendations': []
        }
        
        # åˆ†æå„ä»»å‹™æ¬Šé‡è¶¨å‹¢
        for task in self.current_weights:
            weights = [w[task] for w in self.weights_history]
            trend = 'increasing' if weights[-1] > weights[0] else 'decreasing'
            analysis['weight_trends'][task] = {
                'trend': trend,
                'initial': weights[0],
                'current': weights[-1],
                'change': (weights[-1] - weights[0]) / weights[0] * 100
            }
            
        # æä¾›å»ºè­°
        latest_perf = self.performance_history[-1] if self.performance_history else None
        if latest_perf:
            for task, rate in latest_perf['forgetting_rates'].items():
                if rate > 5.0:
                    analysis['recommendations'].append(
                        f"{task}: éºå¿˜ç‡ {rate:.1f}% > 5%ï¼Œå»ºè­°ç¹¼çºŒå¢åŠ æ¬Šé‡"
                    )
                    
        return analysis