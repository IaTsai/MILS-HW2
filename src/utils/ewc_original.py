"""
Elastic Weight Consolidation (EWC) å¯¦ç¾
ç”¨æ–¼é˜²æ­¢å¤šä»»å‹™å­¸ç¿’ä¸­çš„ç½é›£æ€§éºå¿˜

åŸºæ–¼è«–æ–‡: "Overcoming catastrophic forgetting in neural networks"
(Kirkpatrick et al., 2017)
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from typing import Dict, List, Optional, Tuple, Any, Union
import copy
import time
import numpy as np
from collections import defaultdict


class EWC:
    """
    Elastic Weight Consolidation (EWC) å¯¦ç¾
    
    EWC é€šéè¨ˆç®— Fisher ä¿¡æ¯çŸ©é™£ä¾†è¡¡é‡åƒæ•¸çš„é‡è¦æ€§ï¼Œ
    ä¸¦åœ¨å­¸ç¿’æ–°ä»»å‹™æ™‚æ·»åŠ æ‡²ç½°é …ä¾†ä¿è­·é‡è¦åƒæ•¸ï¼Œ
    å¾è€Œé˜²æ­¢ç½é›£æ€§éºå¿˜ã€‚
    
    Args:
        model: è¦ä¿è­·çš„ç¥ç¶“ç¶²è·¯æ¨¡å‹
        importance: EWC æ‡²ç½°é …çš„é‡è¦æ€§ä¿‚æ•¸ (lambda)
        device: è¨ˆç®—è¨­å‚™
        diagonal_only: æ˜¯å¦åªè¨ˆç®— Fisher çŸ©é™£çš„å°è§’é … (ç¯€çœè¨˜æ†¶é«”)
        ewc_type: EWC é¡å‹ ('l2' æˆ– 'online')
    """
    
    def __init__(self, 
                 model: nn.Module,
                 importance: float = 1000.0,
                 device: Optional[torch.device] = None,
                 diagonal_only: bool = True,
                 ewc_type: str = 'l2'):
        
        self.model = model
        self.importance = importance
        self.device = device if device is not None else next(model.parameters()).device
        self.diagonal_only = diagonal_only
        self.ewc_type = ewc_type
        
        # å­˜å„² Fisher ä¿¡æ¯çŸ©é™£å’Œæœ€å„ªåƒæ•¸
        self.fisher_matrices = {}  # æ¯å€‹ä»»å‹™çš„ Fisher çŸ©é™£
        self.optimal_params = {}   # æ¯å€‹ä»»å‹™çš„æœ€å„ªåƒæ•¸
        self.task_count = 0        # ä»»å‹™è¨ˆæ•¸å™¨
        
        # Online EWC çš„é¡å¤–åƒæ•¸
        if ewc_type == 'online':
            self.gamma = 1.0  # è¡°æ¸›å› å­
            self.consolidated_fisher = {}
            self.consolidated_params = {}
        
        # åƒæ•¸åç¨±æ˜ å°„ (ç”¨æ–¼åƒæ•¸åŒ¹é…)
        self.param_names = [name for name, _ in model.named_parameters() if _.requires_grad]
        
        # çµ±è¨ˆä¿¡æ¯
        self.computation_stats = {
            'fisher_computation_time': [],
            'penalty_computation_time': [],
            'memory_usage': []
        }
    
    def _get_named_parameters(self) -> Dict[str, torch.Tensor]:
        """ç²å–æ¨¡å‹çš„å‘½ååƒæ•¸å­—å…¸"""
        return {name: param for name, param in self.model.named_parameters() if param.requires_grad}
    
    def compute_fisher_matrix(self, 
                            dataloader: DataLoader,
                            task_id: Optional[int] = None,
                            num_samples: Optional[int] = None,
                            verbose: bool = True) -> Dict[str, torch.Tensor]:
        """
        è¨ˆç®— Fisher ä¿¡æ¯çŸ©é™£
        
        Fisher ä¿¡æ¯çŸ©é™£è¡¡é‡äº†æ¯å€‹åƒæ•¸å°æ–¼æ¨¡å‹è¼¸å‡ºçš„é‡è¦æ€§ã€‚
        é€™è£¡ä½¿ç”¨ç¶“é©— Fisher ä¿¡æ¯çŸ©é™£çš„è¿‘ä¼¼è¨ˆç®—ã€‚
        
        Args:
            dataloader: ç”¨æ–¼è¨ˆç®— Fisher çŸ©é™£çš„æ•¸æ“šåŠ è¼‰å™¨
            task_id: ä»»å‹™ID (å¦‚æœç‚º Noneï¼Œå‰‡ä½¿ç”¨ç•¶å‰ä»»å‹™è¨ˆæ•¸)
            num_samples: ä½¿ç”¨çš„æ¨£æœ¬æ•¸é‡ (å¦‚æœç‚º Noneï¼Œå‰‡ä½¿ç”¨æ‰€æœ‰æ¨£æœ¬)
            verbose: æ˜¯å¦é¡¯ç¤ºé€²åº¦ä¿¡æ¯
        
        Returns:
            fisher_matrix: Fisher ä¿¡æ¯çŸ©é™£å­—å…¸
        """
        if task_id is None:
            task_id = self.task_count
        
        if verbose:
            print(f"ğŸ§® è¨ˆç®—ä»»å‹™ {task_id} çš„ Fisher ä¿¡æ¯çŸ©é™£...")
        
        start_time = time.time()
        
        # è¨­ç½®æ¨¡å‹ç‚ºè©•ä¼°æ¨¡å¼
        self.model.eval()
        
        # åˆå§‹åŒ– Fisher çŸ©é™£
        fisher_matrix = {}
        for name, param in self._get_named_parameters().items():
            if self.diagonal_only:
                fisher_matrix[name] = torch.zeros_like(param.data)
            else:
                # å®Œæ•´ Fisher çŸ©é™£éœ€è¦å¤§é‡è¨˜æ†¶é«”ï¼Œé€šå¸¸ä¸å¯¦ç”¨
                fisher_matrix[name] = torch.zeros(param.numel(), param.numel(), device=self.device)
        
        # æ¨£æœ¬è¨ˆæ•¸
        sample_count = 0
        total_samples = len(dataloader.dataset) if num_samples is None else min(num_samples, len(dataloader.dataset))
        
        if verbose:
            print(f"  ä½¿ç”¨ {total_samples} å€‹æ¨£æœ¬è¨ˆç®— Fisher çŸ©é™£")
        
        # æ‰¹æ¬¡è™•ç†
        for batch_idx, batch in enumerate(dataloader):
            if num_samples is not None and sample_count >= num_samples:
                break
            
            # è§£ææ‰¹æ¬¡æ•¸æ“š
            if isinstance(batch, dict):
                # çµ±ä¸€æ•¸æ“šåŠ è¼‰å™¨æ ¼å¼
                images = batch['images'].to(self.device)
                batch_size = images.size(0)
            elif isinstance(batch, (list, tuple)) and len(batch) >= 2:
                # æ¨™æº–æ ¼å¼ (images, labels)
                images = batch[0].to(self.device)
                batch_size = images.size(0)
            else:
                # åªæœ‰åœ–åƒæ•¸æ“š
                images = batch.to(self.device)
                batch_size = images.size(0)
            
            # å‰å‘å‚³æ’­
            outputs = self.model(images)
            
            # è™•ç†å¤šä»»å‹™è¼¸å‡º
            if isinstance(outputs, dict):
                # å¤šä»»å‹™è¼¸å‡ºï¼šè¨ˆç®—æ¯å€‹ä»»å‹™çš„ Fisher çŸ©é™£
                for task_name, task_output in outputs.items():
                    self._accumulate_fisher_from_output(task_output, fisher_matrix, batch_size)
            else:
                # å–®ä»»å‹™è¼¸å‡º
                self._accumulate_fisher_from_output(outputs, fisher_matrix, batch_size)
            
            sample_count += batch_size
            
            if verbose and (batch_idx + 1) % 50 == 0:
                progress = min(sample_count / total_samples * 100, 100)
                print(f"  é€²åº¦: {progress:.1f}% ({sample_count}/{total_samples})")
        
        # æ­£è¦åŒ– Fisher çŸ©é™£
        for name in fisher_matrix:
            fisher_matrix[name] = fisher_matrix[name] / sample_count
        
        # å­˜å„² Fisher çŸ©é™£
        self.fisher_matrices[task_id] = fisher_matrix
        
        # è¨˜éŒ„è¨ˆç®—æ™‚é–“
        computation_time = time.time() - start_time
        self.computation_stats['fisher_computation_time'].append(computation_time)
        
        if verbose:
            print(f"  âœ… Fisher çŸ©é™£è¨ˆç®—å®Œæˆ (è€—æ™‚: {computation_time:.2f}s)")
            
            # é¡¯ç¤º Fisher çŸ©é™£çµ±è¨ˆ
            total_params = sum(f.numel() for f in fisher_matrix.values())
            avg_importance = sum(f.sum().item() for f in fisher_matrix.values()) / total_params
            print(f"  ğŸ“Š å¹³å‡é‡è¦æ€§: {avg_importance:.6f}")
        
        return fisher_matrix
    
    def _accumulate_fisher_from_output(self, 
                                     output: torch.Tensor, 
                                     fisher_matrix: Dict[str, torch.Tensor],
                                     batch_size: int):
        """
        å¾æ¨¡å‹è¼¸å‡ºç´¯ç© Fisher ä¿¡æ¯çŸ©é™£
        
        Args:
            output: æ¨¡å‹è¼¸å‡º
            fisher_matrix: ç•¶å‰çš„ Fisher çŸ©é™£
            batch_size: æ‰¹æ¬¡å¤§å°
        """
        # æ¸…é›¶æ¢¯åº¦
        self.model.zero_grad()
        
        # è¨ˆç®—å°æ•¸ä¼¼ç„¶æ¢¯åº¦
        if output.dim() == 1:
            # åˆ†é¡ä»»å‹™ï¼šå–®å€‹è¼¸å‡º
            log_prob = F.log_softmax(output.unsqueeze(0), dim=1)
            prob = F.softmax(output.unsqueeze(0), dim=1)
        elif output.dim() == 2:
            # åˆ†é¡ä»»å‹™ï¼šæ‰¹æ¬¡è¼¸å‡º
            log_prob = F.log_softmax(output, dim=1)
            prob = F.softmax(output, dim=1)
        elif output.dim() == 4:
            # åˆ†å‰²ä»»å‹™ï¼š(B, C, H, W)
            B, C, H, W = output.shape
            output_flat = output.view(B, C, -1).transpose(1, 2).contiguous().view(-1, C)
            log_prob = F.log_softmax(output_flat, dim=1)
            prob = F.softmax(output_flat, dim=1)
        elif output.dim() == 3:
            # æª¢æ¸¬ä»»å‹™ï¼š(B, N, C)
            B, N, C = output.shape
            output_flat = output.view(-1, C)
            log_prob = F.log_softmax(output_flat, dim=1)
            prob = F.softmax(output_flat, dim=1)
        else:
            raise ValueError(f"Unsupported output dimension: {output.dim()}")
        
        # è¨ˆç®—æœŸæœ›çš„ Fisher ä¿¡æ¯çŸ©é™£
        for class_idx in range(prob.size(1)):
            # é¸æ“‡ç•¶å‰é¡åˆ¥
            if prob.dim() == 2:
                class_prob = prob[:, class_idx].sum()
                class_log_prob = log_prob[:, class_idx].sum()
            else:
                class_prob = prob[:, class_idx].sum()
                class_log_prob = log_prob[:, class_idx].sum()
            
            if class_prob.item() > 1e-8:  # é¿å…æ•¸å€¼ä¸ç©©å®š
                # è¨ˆç®—æ¢¯åº¦
                class_log_prob.backward(retain_graph=True)
                
                # ç´¯ç© Fisher ä¿¡æ¯
                for name, param in self._get_named_parameters().items():
                    if param.grad is not None:
                        if self.diagonal_only:
                            # å°è§’ Fisher çŸ©é™£
                            fisher_matrix[name] += class_prob.item() * (param.grad.data ** 2)
                        else:
                            # å®Œæ•´ Fisher çŸ©é™£ (è¨˜æ†¶é«”å¯†é›†)
                            grad_flat = param.grad.data.view(-1)
                            fisher_matrix[name] += class_prob.item() * torch.outer(grad_flat, grad_flat)
                
                # æ¸…é›¶æ¢¯åº¦
                self.model.zero_grad()
    
    def store_optimal_params(self, task_id: Optional[int] = None):
        """
        å­˜å„²ç•¶å‰ä»»å‹™çš„æœ€å„ªåƒæ•¸
        
        Args:
            task_id: ä»»å‹™ID
        """
        if task_id is None:
            task_id = self.task_count
        
        optimal_params = {}
        for name, param in self._get_named_parameters().items():
            optimal_params[name] = param.data.clone()
        
        self.optimal_params[task_id] = optimal_params
        print(f"ğŸ“¥ å­˜å„²ä»»å‹™ {task_id} çš„æœ€å„ªåƒæ•¸")
    
    def penalty(self, model: Optional[nn.Module] = None) -> torch.Tensor:
        """
        è¨ˆç®— EWC æ‡²ç½°é …
        
        æ‡²ç½°é … = Î»/2 * Î£(F_i * (Î¸_i - Î¸*_i)^2)
        å…¶ä¸­ F_i æ˜¯ Fisher ä¿¡æ¯çŸ©é™£ï¼ŒÎ¸*_i æ˜¯æœ€å„ªåƒæ•¸
        
        Args:
            model: è¦è¨ˆç®—æ‡²ç½°é …çš„æ¨¡å‹ (å¦‚æœç‚º Noneï¼Œä½¿ç”¨ self.model)
        
        Returns:
            penalty: EWC æ‡²ç½°é …
        """
        if model is None:
            model = self.model
        
        start_time = time.time()
        
        penalty = 0.0
        current_params = {name: param for name, param in model.named_parameters() if param.requires_grad}
        
        if self.ewc_type == 'l2':
            # æ¨™æº– EWC: å°æ‰€æœ‰ä»»å‹™è¨ˆç®—æ‡²ç½°é …
            for task_id in self.fisher_matrices.keys():
                if task_id in self.optimal_params:
                    penalty += self._compute_task_penalty(
                        current_params, 
                        self.fisher_matrices[task_id], 
                        self.optimal_params[task_id]
                    )
        
        elif self.ewc_type == 'online':
            # Online EWC: ä½¿ç”¨åˆä½µçš„ Fisher çŸ©é™£
            if self.consolidated_fisher and self.consolidated_params:
                penalty = self._compute_task_penalty(
                    current_params,
                    self.consolidated_fisher,
                    self.consolidated_params
                )
        
        penalty_tensor = torch.tensor(penalty, device=self.device, requires_grad=True)
        penalty_loss = self.importance * penalty_tensor
        
        # è¨˜éŒ„è¨ˆç®—æ™‚é–“
        computation_time = time.time() - start_time
        self.computation_stats['penalty_computation_time'].append(computation_time)
        
        return penalty_loss
    
    def _compute_task_penalty(self, 
                            current_params: Dict[str, torch.Tensor],
                            fisher_matrix: Dict[str, torch.Tensor],
                            optimal_params: Dict[str, torch.Tensor]) -> float:
        """
        è¨ˆç®—å–®å€‹ä»»å‹™çš„æ‡²ç½°é …
        
        Args:
            current_params: ç•¶å‰åƒæ•¸
            fisher_matrix: Fisher ä¿¡æ¯çŸ©é™£
            optimal_params: æœ€å„ªåƒæ•¸
        
        Returns:
            task_penalty: ä»»å‹™æ‡²ç½°é …
        """
        task_penalty = 0.0
        
        for name in fisher_matrix.keys():
            if name in current_params and name in optimal_params:
                # åƒæ•¸å·®ç•°
                param_diff = current_params[name] - optimal_params[name]
                
                if self.diagonal_only:
                    # å°è§’ Fisher çŸ©é™£
                    penalty_term = fisher_matrix[name] * (param_diff ** 2)
                    task_penalty += penalty_term.sum().item()
                else:
                    # å®Œæ•´ Fisher çŸ©é™£
                    param_diff_flat = param_diff.view(-1)
                    penalty_term = torch.dot(param_diff_flat, 
                                           torch.mv(fisher_matrix[name], param_diff_flat))
                    task_penalty += penalty_term.item()
        
        return task_penalty / 2.0
    
    def update_consolidated_fisher(self):
        """
        æ›´æ–°åˆä½µçš„ Fisher çŸ©é™£ (ç”¨æ–¼ Online EWC)
        """
        if self.ewc_type != 'online':
            return
        
        if not self.fisher_matrices:
            return
        
        # ç²å–æœ€æ–°çš„ Fisher çŸ©é™£å’Œåƒæ•¸
        latest_task_id = max(self.fisher_matrices.keys())
        latest_fisher = self.fisher_matrices[latest_task_id]
        latest_params = self.optimal_params[latest_task_id]
        
        if not self.consolidated_fisher:
            # ç¬¬ä¸€å€‹ä»»å‹™ï¼šç›´æ¥è¤‡è£½
            self.consolidated_fisher = copy.deepcopy(latest_fisher)
            self.consolidated_params = copy.deepcopy(latest_params)
        else:
            # å¾ŒçºŒä»»å‹™ï¼šåŠ æ¬Šåˆä½µ
            for name in latest_fisher.keys():
                if name in self.consolidated_fisher:
                    # åˆä½µ Fisher çŸ©é™£
                    self.consolidated_fisher[name] = (
                        self.gamma * self.consolidated_fisher[name] + 
                        latest_fisher[name]
                    )
                    
                    # æ›´æ–°åˆä½µåƒæ•¸ (åŠ æ¬Šå¹³å‡)
                    self.consolidated_params[name] = (
                        self.gamma * self.consolidated_params[name] + 
                        latest_params[name]
                    ) / (self.gamma + 1.0)
        
        print(f"ğŸ”„ æ›´æ–°åˆä½µçš„ Fisher çŸ©é™£ (ä»»å‹™ {latest_task_id})")
    
    def finish_task(self, 
                   dataloader: DataLoader, 
                   task_id: Optional[int] = None,
                   verbose: bool = True) -> int:
        """
        å®Œæˆç•¶å‰ä»»å‹™çš„ EWC è¨­ç½®
        
        Args:
            dataloader: ç•¶å‰ä»»å‹™çš„æ•¸æ“šåŠ è¼‰å™¨
            task_id: ä»»å‹™ID
            verbose: æ˜¯å¦é¡¯ç¤ºè©³ç´°ä¿¡æ¯
        
        Returns:
            task_id: å¯¦éš›ä½¿ç”¨çš„ä»»å‹™ID
        """
        if task_id is None:
            task_id = self.task_count
        
        if verbose:
            print(f"ğŸ¯ å®Œæˆä»»å‹™ {task_id} çš„ EWC è¨­ç½®...")
        
        # è¨ˆç®— Fisher çŸ©é™£
        self.compute_fisher_matrix(dataloader, task_id=task_id, verbose=verbose)
        
        # å­˜å„²æœ€å„ªåƒæ•¸
        self.store_optimal_params(task_id=task_id)
        
        # æ›´æ–°åˆä½µçš„ Fisher çŸ©é™£ (Online EWC)
        if self.ewc_type == 'online':
            self.update_consolidated_fisher()
        
        # å¢åŠ ä»»å‹™è¨ˆæ•¸
        if task_id == self.task_count:
            self.task_count += 1
        
        if verbose:
            print(f"âœ… ä»»å‹™ {task_id} çš„ EWC è¨­ç½®å®Œæˆ")
        
        return task_id
    
    def get_memory_usage(self) -> Dict[str, float]:
        """
        ç²å– EWC çš„è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
        
        Returns:
            memory_info: è¨˜æ†¶é«”ä½¿ç”¨ä¿¡æ¯ (MB)
        """
        fisher_memory = 0
        params_memory = 0
        
        # è¨ˆç®— Fisher çŸ©é™£è¨˜æ†¶é«”
        for fisher_matrix in self.fisher_matrices.values():
            for tensor in fisher_matrix.values():
                fisher_memory += tensor.numel() * tensor.element_size()
        
        # è¨ˆç®—åƒæ•¸è¨˜æ†¶é«”
        for params in self.optimal_params.values():
            for tensor in params.values():
                params_memory += tensor.numel() * tensor.element_size()
        
        # åˆä½µçš„ Fisher çŸ©é™£è¨˜æ†¶é«”
        consolidated_memory = 0
        if hasattr(self, 'consolidated_fisher') and self.consolidated_fisher:
            for tensor in self.consolidated_fisher.values():
                consolidated_memory += tensor.numel() * tensor.element_size()
        
        total_memory = fisher_memory + params_memory + consolidated_memory
        
        memory_info = {
            'fisher_matrices_mb': fisher_memory / (1024 ** 2),
            'optimal_params_mb': params_memory / (1024 ** 2),
            'consolidated_mb': consolidated_memory / (1024 ** 2),
            'total_mb': total_memory / (1024 ** 2),
            'num_tasks': len(self.fisher_matrices)
        }
        
        return memory_info
    
    def get_computation_stats(self) -> Dict[str, Any]:
        """
        ç²å–è¨ˆç®—çµ±è¨ˆä¿¡æ¯
        
        Returns:
            stats: è¨ˆç®—çµ±è¨ˆä¿¡æ¯
        """
        stats = {
            'avg_fisher_time': np.mean(self.computation_stats['fisher_computation_time']) if self.computation_stats['fisher_computation_time'] else 0,
            'avg_penalty_time': np.mean(self.computation_stats['penalty_computation_time']) if self.computation_stats['penalty_computation_time'] else 0,
            'total_fisher_computations': len(self.computation_stats['fisher_computation_time']),
            'total_penalty_computations': len(self.computation_stats['penalty_computation_time']),
            'memory_usage': self.get_memory_usage()
        }
        
        return stats
    
    def save_ewc_data(self, save_path: str):
        """
        ä¿å­˜ EWC æ•¸æ“š
        
        Args:
            save_path: ä¿å­˜è·¯å¾‘
        """
        ewc_data = {
            'fisher_matrices': self.fisher_matrices,
            'optimal_params': self.optimal_params,
            'task_count': self.task_count,
            'importance': self.importance,
            'ewc_type': self.ewc_type,
            'computation_stats': self.computation_stats
        }
        
        if self.ewc_type == 'online':
            ewc_data.update({
                'consolidated_fisher': getattr(self, 'consolidated_fisher', {}),
                'consolidated_params': getattr(self, 'consolidated_params', {}),
                'gamma': getattr(self, 'gamma', 1.0)
            })
        
        torch.save(ewc_data, save_path)
        print(f"ğŸ’¾ EWC æ•¸æ“šå·²ä¿å­˜åˆ°: {save_path}")
    
    def load_ewc_data(self, load_path: str):
        """
        è¼‰å…¥ EWC æ•¸æ“š
        
        Args:
            load_path: è¼‰å…¥è·¯å¾‘
        """
        ewc_data = torch.load(load_path, map_location=self.device)
        
        self.fisher_matrices = ewc_data.get('fisher_matrices', {})
        self.optimal_params = ewc_data.get('optimal_params', {})
        self.task_count = ewc_data.get('task_count', 0)
        self.importance = ewc_data.get('importance', self.importance)
        self.ewc_type = ewc_data.get('ewc_type', self.ewc_type)
        self.computation_stats = ewc_data.get('computation_stats', self.computation_stats)
        
        if self.ewc_type == 'online':
            self.consolidated_fisher = ewc_data.get('consolidated_fisher', {})
            self.consolidated_params = ewc_data.get('consolidated_params', {})
            self.gamma = ewc_data.get('gamma', 1.0)
        
        print(f"ğŸ“‚ EWC æ•¸æ“šå·²å¾ {load_path} è¼‰å…¥")


def ewc_loss(current_loss: torch.Tensor, 
            ewc_handler: EWC, 
            model: Optional[nn.Module] = None) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    è¨ˆç®—åŒ…å« EWC æ‡²ç½°é …çš„ç¸½æå¤±
    
    Args:
        current_loss: ç•¶å‰ä»»å‹™çš„æå¤±
        ewc_handler: EWC è™•ç†å™¨
        model: æ¨¡å‹ (å¦‚æœç‚º Noneï¼Œä½¿ç”¨ ewc_handler.model)
    
    Returns:
        total_loss: åŒ…å« EWC æ‡²ç½°é …çš„ç¸½æå¤±
        ewc_penalty: EWC æ‡²ç½°é …
    """
    ewc_penalty = ewc_handler.penalty(model)
    total_loss = current_loss + ewc_penalty
    
    return total_loss, ewc_penalty


def create_ewc_handler(model: nn.Module, 
                      importance: float = 1000.0,
                      ewc_type: str = 'l2',
                      **kwargs) -> EWC:
    """
    å‰µå»º EWC è™•ç†å™¨çš„å·¥å» å‡½æ•¸
    
    Args:
        model: ç¥ç¶“ç¶²è·¯æ¨¡å‹
        importance: é‡è¦æ€§ä¿‚æ•¸
        ewc_type: EWC é¡å‹
        **kwargs: å…¶ä»–åƒæ•¸
    
    Returns:
        ewc_handler: EWC è™•ç†å™¨
    """
    return EWC(model=model, importance=importance, ewc_type=ewc_type, **kwargs)


if __name__ == "__main__":
    # ç°¡å–®æ¸¬è©¦ä»£ç¢¼
    import torch.nn as nn
    
    # å‰µå»ºç°¡å–®æ¨¡å‹
    model = nn.Sequential(
        nn.Linear(10, 20),
        nn.ReLU(),
        nn.Linear(20, 5)
    )
    
    # å‰µå»º EWC è™•ç†å™¨
    ewc = create_ewc_handler(model, importance=1000.0)
    
    # å‰µå»ºè™›æ“¬æ•¸æ“š
    data = torch.randn(100, 10)
    labels = torch.randint(0, 5, (100,))
    dataset = torch.utils.data.TensorDataset(data, labels)
    dataloader = torch.utils.data.DataLoader(dataset, batch_size=10)
    
    # è¨ˆç®— Fisher çŸ©é™£
    fisher_matrix = ewc.compute_fisher_matrix(dataloader, verbose=True)
    
    # å­˜å„²æœ€å„ªåƒæ•¸
    ewc.store_optimal_params()
    
    # è¨ˆç®—æ‡²ç½°é …
    penalty = ewc.penalty()
    
    print(f"âœ… EWC æ¸¬è©¦å®Œæˆï¼")
    print(f"ğŸ“Š Fisher çŸ©é™£å±¤æ•¸: {len(fisher_matrix)}")
    print(f"ğŸ’° EWC æ‡²ç½°é …: {penalty.item():.6f}")
    print(f"ğŸ’¾ è¨˜æ†¶é«”ä½¿ç”¨: {ewc.get_memory_usage()}")
    print(f"ğŸ“ˆ è¨ˆç®—çµ±è¨ˆ: {ewc.get_computation_stats()}")