"""
é ¸éƒ¨ç¶²è·¯å¯¦ç¾ - Feature Pyramid Network (FPN)
ç”¨æ–¼å¤šå°ºåº¦ç‰¹å¾µèåˆï¼Œæ”¯æ´å¤šä»»å‹™å­¸ç¿’
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List, Optional, Tuple


class FeaturePyramidNetwork(nn.Module):
    """
    Feature Pyramid Network (FPN) é ¸éƒ¨ç¶²è·¯
    
    å¯¦ç¾å¤šå°ºåº¦ç‰¹å¾µèåˆï¼Œå°‡éª¨å¹¹ç¶²è·¯çš„ä¸åŒå±¤ç´šç‰¹å¾µ
    èåˆæˆçµ±ä¸€çš„ç‰¹å¾µé‡‘å­—å¡”ï¼Œé©ç”¨æ–¼å¤šä»»å‹™å­¸ç¿’
    
    Args:
        in_channels_list: è¼¸å…¥ç‰¹å¾µåœ–çš„é€šé“æ•¸åˆ—è¡¨ [16, 24, 48, 96]
        out_channels: è¼¸å‡ºç‰¹å¾µåœ–çš„çµ±ä¸€é€šé“æ•¸ï¼Œé è¨­256
        extra_blocks: æ˜¯å¦æ·»åŠ é¡å¤–çš„ä¸‹æ¡æ¨£å¡Š
    """
    
    def __init__(self, 
                 in_channels_list: List[int] = [16, 24, 48, 96], 
                 out_channels: int = 256,
                 extra_blocks: Optional[int] = None):
        super().__init__()
        
        self.in_channels_list = in_channels_list
        self.out_channels = out_channels
        self.num_feature_levels = len(in_channels_list)
        
        # æ©«å‘é€£æ¥å±¤ (1x1 å·ç©é™ç¶­)
        # å°‡ä¸åŒé€šé“æ•¸çš„ç‰¹å¾µåœ–çµ±ä¸€åˆ° out_channels
        self.lateral_convs = nn.ModuleList()
        for in_channels in in_channels_list:
            lateral_conv = nn.Conv2d(
                in_channels, 
                out_channels, 
                kernel_size=1, 
                stride=1, 
                padding=0
            )
            self.lateral_convs.append(lateral_conv)
        
        # èåˆå·ç©å±¤ (3x3 å·ç©æ¶ˆé™¤æ··ç–Š)
        # å°ä¸Šæ¡æ¨£å¾Œçš„ç‰¹å¾µé€²è¡Œå¹³æ»‘è™•ç†
        self.fpn_convs = nn.ModuleList()
        for _ in range(self.num_feature_levels):
            fpn_conv = nn.Conv2d(
                out_channels,
                out_channels,
                kernel_size=3,
                stride=1,
                padding=1
            )
            self.fpn_convs.append(fpn_conv)
        
        # é¡å¤–çš„ä¸‹æ¡æ¨£å¡Š (ç”¨æ–¼æ›´å¤§æ„Ÿå—é‡)
        self.extra_blocks = None
        if extra_blocks:
            self.extra_blocks = nn.ModuleList()
            for i in range(extra_blocks):
                extra_conv = nn.Conv2d(
                    out_channels,
                    out_channels,
                    kernel_size=3,
                    stride=2,
                    padding=1
                )
                self.extra_blocks.append(extra_conv)
        
        self._initialize_weights()
    
    def _initialize_weights(self):
        """åˆå§‹åŒ–ç¶²è·¯æ¬Šé‡"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
    
    def forward(self, features: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        """
        å‰å‘å‚³æ’­
        
        Args:
            features: éª¨å¹¹ç¶²è·¯è¼¸å‡ºçš„å¤šå°ºåº¦ç‰¹å¾µ
                     {'layer1': tensor, 'layer2': tensor, 'layer3': tensor, 'layer4': tensor}
        
        Returns:
            fused_features: èåˆå¾Œçš„ç‰¹å¾µé‡‘å­—å¡”
                           {'P2': tensor, 'P3': tensor, 'P4': tensor, 'P5': tensor}
        """
        # æå–ç‰¹å¾µä¸¦æŒ‰é †åºæ’åˆ— (å¾å°å°ºåº¦åˆ°å¤§å°ºåº¦)
        feature_list = []
        layer_names = ['layer1', 'layer2', 'layer3', 'layer4']
        
        for layer_name in layer_names:
            if layer_name in features:
                feature_list.append(features[layer_name])
            else:
                raise KeyError(f"Missing feature layer: {layer_name}")
        
        # è‡ªé ‚å‘ä¸‹è·¯å¾‘ (Top-down pathway)
        # å¾æœ€å°å°ºåº¦ç‰¹å¾µé–‹å§‹
        laterals = []
        
        # 1. é€šéæ©«å‘é€£æ¥è™•ç†æ‰€æœ‰ç‰¹å¾µ
        for i, feature in enumerate(feature_list):
            lateral = self.lateral_convs[i](feature)
            laterals.append(lateral)
        
        # 2. è‡ªé ‚å‘ä¸‹èåˆ
        # å¾æœ€é«˜å±¤(æœ€å°è§£æåº¦)é–‹å§‹
        fpn_features = []
        
        # æœ€é«˜å±¤ç‰¹å¾µç›´æ¥ä½¿ç”¨
        prev_feature = laterals[-1]
        fpn_features.append(self.fpn_convs[-1](prev_feature))
        
        # è‡ªé ‚å‘ä¸‹èåˆå…¶ä»–å±¤
        for i in range(len(laterals) - 2, -1, -1):
            # ä¸Šæ¡æ¨£åˆ°ç•¶å‰å±¤çš„å¤§å°
            upsampled = F.interpolate(
                prev_feature, 
                size=laterals[i].shape[-2:], 
                mode='nearest'
            )
            
            # èˆ‡æ©«å‘é€£æ¥ç›¸åŠ 
            fused = upsampled + laterals[i]
            
            # é€šé 3x3 å·ç©å¹³æ»‘
            fpn_feature = self.fpn_convs[i](fused)
            fpn_features.append(fpn_feature)
            
            prev_feature = fused
        
        # åè½‰åˆ—è¡¨ï¼Œä½¿å…¶æŒ‰ç…§å¾å¤§å°ºåº¦åˆ°å°å°ºåº¦æ’åˆ—
        fpn_features = fpn_features[::-1]
        
        # 3. æ§‹å»ºè¼¸å‡ºå­—å…¸
        output_features = {}
        pyramid_levels = ['P2', 'P3', 'P4', 'P5']
        
        for i, fpn_feature in enumerate(fpn_features):
            output_features[pyramid_levels[i]] = fpn_feature
        
        # 4. æ·»åŠ é¡å¤–çš„ä¸‹æ¡æ¨£ç‰¹å¾µ (å¦‚æœæœ‰)
        if self.extra_blocks:
            last_feature = fpn_features[-1]
            for i, extra_conv in enumerate(self.extra_blocks):
                last_feature = extra_conv(last_feature)
                output_features[f'P{6+i}'] = last_feature
        
        return output_features
    
    def get_parameter_count(self):
        """ç²å–åƒæ•¸æ•¸é‡çµ±è¨ˆ"""
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        
        # è©³ç´°çµ±è¨ˆ
        lateral_params = sum(p.numel() for conv in self.lateral_convs for p in conv.parameters())
        fpn_params = sum(p.numel() for conv in self.fpn_convs for p in conv.parameters())
        extra_params = 0
        if self.extra_blocks:
            extra_params = sum(p.numel() for conv in self.extra_blocks for p in conv.parameters())
        
        return {
            'total_parameters': total_params,
            'trainable_parameters': trainable_params,
            'lateral_conv_parameters': lateral_params,
            'fpn_conv_parameters': fpn_params,
            'extra_block_parameters': extra_params
        }
    
    def get_feature_info(self):
        """ç²å–ç‰¹å¾µä¿¡æ¯"""
        return {
            'input_channels': self.in_channels_list,
            'output_channels': self.out_channels,
            'num_feature_levels': self.num_feature_levels,
            'has_extra_blocks': self.extra_blocks is not None,
            'output_strides': {
                'P2': 4,   # 1/4 resolution
                'P3': 8,   # 1/8 resolution
                'P4': 16,  # 1/16 resolution
                'P5': 32   # 1/32 resolution
            }
        }


class LightweightNeck(nn.Module):
    """
    è¼•é‡åŒ–é ¸éƒ¨ç¶²è·¯ (æ›¿ä»£æ–¹æ¡ˆ)
    
    ä½¿ç”¨æ›´ç°¡å–®çš„ç‰¹å¾µèåˆç­–ç•¥ï¼Œåƒæ•¸é‡æ›´å°‘
    é©ç”¨æ–¼è³‡æºå—é™çš„ç’°å¢ƒ
    
    Args:
        in_channels_list: è¼¸å…¥ç‰¹å¾µåœ–çš„é€šé“æ•¸åˆ—è¡¨
        out_channels: è¼¸å‡ºç‰¹å¾µåœ–çš„çµ±ä¸€é€šé“æ•¸
        use_bn: æ˜¯å¦ä½¿ç”¨ BatchNorm
    """
    
    def __init__(self, 
                 in_channels_list: List[int] = [16, 24, 48, 96],
                 out_channels: int = 128,
                 use_bn: bool = True):
        super().__init__()
        
        self.in_channels_list = in_channels_list
        self.out_channels = out_channels
        self.use_bn = use_bn
        
        # ç°¡å–®çš„ 1x1 å·ç©çµ±ä¸€é€šé“æ•¸
        self.channel_reducers = nn.ModuleList()
        for in_channels in in_channels_list:
            layers = [nn.Conv2d(in_channels, out_channels, 1, 1, 0)]
            if use_bn:
                layers.append(nn.BatchNorm2d(out_channels))
            layers.append(nn.ReLU(inplace=True))
            
            self.channel_reducers.append(nn.Sequential(*layers))
        
        # å¯é¸çš„èåˆå·ç©
        self.fusion_conv = nn.Sequential(
            nn.Conv2d(out_channels, out_channels, 3, 1, 1),
            nn.BatchNorm2d(out_channels) if use_bn else nn.Identity(),
            nn.ReLU(inplace=True)
        )
        
        self._initialize_weights()
    
    def _initialize_weights(self):
        """åˆå§‹åŒ–æ¬Šé‡"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.ones_(m.weight)
                nn.init.zeros_(m.bias)
    
    def forward(self, features: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        """å‰å‘å‚³æ’­"""
        fused_features = {}
        layer_names = ['layer1', 'layer2', 'layer3', 'layer4']
        output_names = ['P2', 'P3', 'P4', 'P5']
        
        for i, (layer_name, output_name) in enumerate(zip(layer_names, output_names)):
            if layer_name in features:
                # é€šé“æ•¸çµ±ä¸€
                reduced_feature = self.channel_reducers[i](features[layer_name])
                # å¯é¸çš„èåˆå·ç©
                fused_feature = self.fusion_conv(reduced_feature)
                fused_features[output_name] = fused_feature
            else:
                raise KeyError(f"Missing feature layer: {layer_name}")
        
        return fused_features
    
    def get_parameter_count(self):
        """ç²å–åƒæ•¸æ•¸é‡çµ±è¨ˆ"""
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        
        return {
            'total_parameters': total_params,
            'trainable_parameters': trainable_params
        }


# å‘å¾Œå…¼å®¹æ€§
class FPN(nn.Module):
    """åŸå§‹ FPN é¡ï¼Œä¿æŒå‘å¾Œå…¼å®¹"""
    def __init__(self, in_channels, out_channel=256):
        super(FPN, self).__init__()
        
        self.lateral_convs = nn.ModuleList()
        self.fpn_convs = nn.ModuleList()
        
        for in_channel in in_channels:
            l_conv = nn.Conv2d(in_channel, out_channel, kernel_size=1)
            fpn_conv = nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1)
            self.lateral_convs.append(l_conv)
            self.fpn_convs.append(fpn_conv)
        
        self.num_ins = len(in_channels)
    
    def forward(self, inputs):
        assert len(inputs) == self.num_ins
        
        laterals = []
        for i, lateral_conv in enumerate(self.lateral_convs):
            laterals.append(lateral_conv(inputs[i]))
        
        for i in range(self.num_ins - 1, 0, -1):
            laterals[i - 1] += F.interpolate(
                laterals[i], 
                size=laterals[i - 1].shape[2:], 
                mode='nearest'
            )
        
        outs = []
        for i, fpn_conv in enumerate(self.fpn_convs):
            outs.append(fpn_conv(laterals[i]))
        
        return tuple(outs)


def create_neck(neck_type='fpn', **kwargs):
    """
    é ¸éƒ¨ç¶²è·¯å·¥å» å‡½æ•¸
    
    Args:
        neck_type: ç¶²è·¯é¡å‹ 'fpn' æˆ– 'lightweight'
        **kwargs: å…¶ä»–åƒæ•¸
    
    Returns:
        neck: é ¸éƒ¨ç¶²è·¯å¯¦ä¾‹
    """
    if neck_type == 'fpn':
        return FeaturePyramidNetwork(**kwargs)
    elif neck_type == 'lightweight':
        return LightweightNeck(**kwargs)
    else:
        raise ValueError(f"Unsupported neck type: {neck_type}")


if __name__ == "__main__":
    # æ¸¬è©¦ä»£ç¢¼
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # å‰µå»º FPN é ¸éƒ¨ç¶²è·¯
    fpn = create_neck('fpn', in_channels_list=[16, 24, 48, 96], out_channels=256)
    fpn = fpn.to(device)
    
    # æ¨¡æ“¬éª¨å¹¹ç¶²è·¯è¼¸å‡º
    batch_size = 2
    input_features = {
        'layer1': torch.randn(batch_size, 16, 128, 128).to(device),  # 1/4
        'layer2': torch.randn(batch_size, 24, 64, 64).to(device),    # 1/8
        'layer3': torch.randn(batch_size, 48, 32, 32).to(device),    # 1/16
        'layer4': torch.randn(batch_size, 96, 16, 16).to(device)     # 1/32
    }
    
    # å‰å‘å‚³æ’­
    with torch.no_grad():
        output_features = fpn(input_features)
    
    # è¼¸å‡ºçµæœ
    print("âœ… FPN é ¸éƒ¨ç¶²è·¯æ¸¬è©¦æˆåŠŸï¼")
    print(f"ğŸ“Š åƒæ•¸çµ±è¨ˆ: {fpn.get_parameter_count()}")
    print(f"ğŸ“‹ ç‰¹å¾µä¿¡æ¯: {fpn.get_feature_info()}")
    
    print("\nğŸ” è¼¸å‡ºç‰¹å¾µå½¢ç‹€:")
    for name, feature in output_features.items():
        print(f"  {name}: {feature.shape}")
    
    # æ¸¬è©¦è¼•é‡åŒ–ç‰ˆæœ¬
    print("\n" + "="*50)
    lightweight_neck = create_neck('lightweight', in_channels_list=[16, 24, 48, 96], out_channels=128)
    lightweight_neck = lightweight_neck.to(device)
    
    with torch.no_grad():
        lightweight_output = lightweight_neck(input_features)
    
    print("âœ… è¼•é‡åŒ–é ¸éƒ¨ç¶²è·¯æ¸¬è©¦æˆåŠŸï¼")
    print(f"ğŸ“Š åƒæ•¸çµ±è¨ˆ: {lightweight_neck.get_parameter_count()}")
    
    print("\nğŸ” è¼¸å‡ºç‰¹å¾µå½¢ç‹€:")
    for name, feature in lightweight_output.items():
        print(f"  {name}: {feature.shape}")