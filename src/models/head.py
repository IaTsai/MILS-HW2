"""
çµ±ä¸€å¤šä»»å‹™é ­éƒ¨å¯¦ç¾
ç”¨æ–¼åŒæ™‚è™•ç†æª¢æ¸¬ã€åˆ†å‰²ã€åˆ†é¡ä¸‰å€‹ä»»å‹™çš„çµ±ä¸€é ­éƒ¨è¨­è¨ˆ
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List, Optional, Union, Tuple


class UnifiedMultiTaskHead(nn.Module):
    """
    çµ±ä¸€å¤šä»»å‹™é ­éƒ¨ - æ ¸å¿ƒè¨­è¨ˆ
    
    æ¡ç”¨å…±äº«ç‰¹å¾µæå– + ä»»å‹™ç‰¹å®šåˆ†æ”¯çš„è¨­è¨ˆç­–ç•¥ï¼š
    - 2å±¤å…±äº«å·ç©ç‰¹å¾µæå– (åƒæ•¸é«˜æ•ˆ)
    - 3å€‹ä»»å‹™ç‰¹å®šè¼¸å‡ºåˆ†æ”¯ (ä¿æŒä»»å‹™ç‰¹ç•°æ€§)
    - æ”¯æ´å¤šå°ºåº¦ç‰¹å¾µèåˆ
    
    Args:
        in_channels: è¼¸å…¥ç‰¹å¾µé€šé“æ•¸ (ä¾†è‡ªFPN)
        num_det_classes: æª¢æ¸¬é¡åˆ¥æ•¸
        num_seg_classes: åˆ†å‰²é¡åˆ¥æ•¸  
        num_cls_classes: åˆ†é¡é¡åˆ¥æ•¸
        shared_channels: å…±äº«ç‰¹å¾µé€šé“æ•¸
    """
    
    def __init__(self, 
                 in_channels: int = 128,
                 num_det_classes: int = 10,
                 num_seg_classes: int = 21, 
                 num_cls_classes: int = 10,
                 shared_channels: int = 256):
        super().__init__()
        
        self.in_channels = in_channels
        self.shared_channels = shared_channels
        self.num_det_classes = num_det_classes
        self.num_seg_classes = num_seg_classes
        self.num_cls_classes = num_cls_classes
        
        # å…±äº«ç‰¹å¾µæå–å±¤ (2å±¤)
        self.shared_conv1 = nn.Sequential(
            nn.Conv2d(in_channels, shared_channels, 3, 1, 1),
            nn.BatchNorm2d(shared_channels),
            nn.ReLU(inplace=True)
        )
        
        self.shared_conv2 = nn.Sequential(
            nn.Conv2d(shared_channels, shared_channels, 3, 1, 1),
            nn.BatchNorm2d(shared_channels),
            nn.ReLU(inplace=True)
        )
        
        # æª¢æ¸¬åˆ†æ”¯ (anchor-free FCOS-style)
        self.detection_cls = nn.Conv2d(shared_channels, num_det_classes, 3, 1, 1)
        self.detection_reg = nn.Conv2d(shared_channels, 4, 3, 1, 1)  # l, t, r, b
        self.detection_centerness = nn.Conv2d(shared_channels, 1, 3, 1, 1)
        
        # åˆ†å‰²åˆ†æ”¯ (è¼•é‡åŒ–UNet-style)
        self.segmentation_conv = nn.Sequential(
            nn.Conv2d(shared_channels, shared_channels // 2, 3, 1, 1),
            nn.BatchNorm2d(shared_channels // 2),
            nn.ReLU(inplace=True),
            nn.Conv2d(shared_channels // 2, num_seg_classes, 1, 1, 0)
        )
        
        # åˆ†é¡åˆ†æ”¯ (å…¨å±€å¹³å‡æ± åŒ–)
        self.classification_gap = nn.AdaptiveAvgPool2d(1)
        self.classification_fc = nn.Sequential(
            nn.Linear(shared_channels, shared_channels // 4),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(shared_channels // 4, num_cls_classes)
        )
        
        self._initialize_weights()
    
    def _initialize_weights(self):
        """åˆå§‹åŒ–æ¬Šé‡"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.ones_(m.weight)
                nn.init.zeros_(m.bias)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
        
        # ç‰¹æ®Šåˆå§‹åŒ–æª¢æ¸¬åˆ†æ”¯çš„bias
        nn.init.constant_(self.detection_cls.bias, -2.19)  # å°æ‡‰0.1çš„å…ˆé©—æ¦‚ç‡
    
    def forward(self, features: Dict[str, torch.Tensor], 
                task_type: str = 'all') -> Dict[str, torch.Tensor]:
        """
        å‰å‘å‚³æ’­
        
        Args:
            features: FPNè¼¸å‡ºçš„å¤šå°ºåº¦ç‰¹å¾µ {'P2': tensor, 'P3': tensor, 'P4': tensor, 'P5': tensor}
            task_type: ä»»å‹™é¡å‹ 'all', 'detection', 'segmentation', 'classification'
        
        Returns:
            outputs: ä»»å‹™è¼¸å‡ºå­—å…¸
        """
        # é¸æ“‡ä¸»è¦ç‰¹å¾µå±¤ (P3: 1/8 resolution, å¹³è¡¡åˆ†è¾¨ç‡å’Œèªç¾©)
        if 'P3' in features:
            main_feature = features['P3']
        elif 'P2' in features:
            main_feature = features['P2']
        else:
            # ä½¿ç”¨ç¬¬ä¸€å€‹å¯ç”¨ç‰¹å¾µ
            main_feature = list(features.values())[0]
        
        # å…±äº«ç‰¹å¾µæå–
        shared_feat = self.shared_conv1(main_feature)
        shared_feat = self.shared_conv2(shared_feat)
        
        outputs = {}
        
        # æª¢æ¸¬ä»»å‹™
        if task_type in ['all', 'detection']:
            det_cls = self.detection_cls(shared_feat)
            det_reg = self.detection_reg(shared_feat)
            det_centerness = self.detection_centerness(shared_feat)
            
            # è½‰æ›ç‚ºæ¨™æº–æ ¼å¼: (B, H*W, 6) - cx,cy,w,h,conf,cls
            B, _, H, W = det_cls.shape
            
            # åˆ†é¡logits: (B, num_classes, H, W) -> (B, H*W, num_classes)
            det_cls = det_cls.permute(0, 2, 3, 1).reshape(B, H*W, self.num_det_classes)
            
            # å›æ­¸: (B, 4, H, W) -> (B, H*W, 4)
            det_reg = det_reg.permute(0, 2, 3, 1).reshape(B, H*W, 4)
            det_reg = F.relu(det_reg)  # ç¢ºä¿æ­£å€¼
            
            # ä¸­å¿ƒåº¦: (B, 1, H, W) -> (B, H*W, 1)
            det_centerness = det_centerness.permute(0, 2, 3, 1).reshape(B, H*W, 1)
            det_centerness = torch.sigmoid(det_centerness)
            
            # çµ„åˆè¼¸å‡º: cx, cy, w, h, centerness, class_logits
            # ç”Ÿæˆç¶²æ ¼åº§æ¨™
            device = det_cls.device
            y_coords, x_coords = torch.meshgrid(
                torch.arange(H, device=device, dtype=torch.float32),
                torch.arange(W, device=device, dtype=torch.float32),
                indexing='ij'
            )
            
            # åº§æ¨™æ­¸ä¸€åŒ–åˆ°[0,1]
            x_coords = (x_coords + 0.5) / W
            y_coords = (y_coords + 0.5) / H
            
            coords = torch.stack([x_coords, y_coords], dim=-1)  # (H, W, 2)
            coords = coords.reshape(H*W, 2).unsqueeze(0).expand(B, -1, -1)  # (B, H*W, 2)
            
            # FCOSæ ¼å¼è½‰æ›ç‚ºä¸­å¿ƒé»æ ¼å¼
            # l, t, r, b -> cx, cy, w, h
            l, t, r, b = det_reg[..., 0:1], det_reg[..., 1:2], det_reg[..., 2:3], det_reg[..., 3:4]
            
            cx = coords[..., 0:1] - l + (l + r) / 2
            cy = coords[..., 1:2] - t + (t + b) / 2
            w = l + r
            h = t + b
            
            # æ‰¾å‡ºæœ€é«˜ç½®ä¿¡åº¦é¡åˆ¥
            max_cls_scores, max_cls_indices = torch.max(torch.sigmoid(det_cls), dim=-1, keepdim=True)
            
            # ç¶œåˆç½®ä¿¡åº¦ (åˆ†é¡ç½®ä¿¡åº¦ * ä¸­å¿ƒåº¦)
            confidence = max_cls_scores * det_centerness
            
            # æœ€çµ‚æª¢æ¸¬è¼¸å‡º: (B, H*W, 6)
            detection_output = torch.cat([cx, cy, w, h, confidence, max_cls_indices.float()], dim=-1)
            
            outputs['detection'] = detection_output
        
        # åˆ†å‰²ä»»å‹™
        if task_type in ['all', 'segmentation']:
            seg_out = self.segmentation_conv(shared_feat)
            
            # ä¸Šæ¡æ¨£åˆ°åŸåœ–å°ºå¯¸ (å‡è¨­è¼¸å…¥ç‚º512x512, P3ç‚º64x64)
            target_size = (512, 512)  # æ ¹æ“šå¯¦éš›è¼¸å…¥å°ºå¯¸èª¿æ•´
            seg_out = F.interpolate(
                seg_out, 
                size=target_size, 
                mode='bilinear', 
                align_corners=False
            )
            
            outputs['segmentation'] = seg_out  # (B, num_seg_classes, H, W)
        
        # åˆ†é¡ä»»å‹™
        if task_type in ['all', 'classification']:
            cls_feat = self.classification_gap(shared_feat)  # (B, C, 1, 1)
            cls_feat = cls_feat.flatten(1)  # (B, C)
            cls_out = self.classification_fc(cls_feat)
            
            outputs['classification'] = cls_out  # (B, num_cls_classes)
        
        return outputs
    
    def get_parameter_count(self):
        """ç²å–åƒæ•¸æ•¸é‡çµ±è¨ˆ"""
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        
        # åˆ†çµ„çµ±è¨ˆ
        shared_params = (
            sum(p.numel() for p in self.shared_conv1.parameters()) + 
            sum(p.numel() for p in self.shared_conv2.parameters())
        )
        
        detection_params = (
            sum(p.numel() for p in self.detection_cls.parameters()) +
            sum(p.numel() for p in self.detection_reg.parameters()) +
            sum(p.numel() for p in self.detection_centerness.parameters())
        )
        
        segmentation_params = sum(p.numel() for p in self.segmentation_conv.parameters())
        
        classification_params = sum(p.numel() for p in self.classification_fc.parameters())
        
        return {
            'total_parameters': total_params,
            'trainable_parameters': trainable_params,
            'shared_parameters': shared_params,
            'detection_parameters': detection_params,
            'segmentation_parameters': segmentation_params,
            'classification_parameters': classification_params
        }
    
    def get_output_info(self):
        """ç²å–è¼¸å‡ºä¿¡æ¯"""
        return {
            'detection_format': 'FCOS-style (cx, cy, w, h, confidence, class)',
            'detection_shape': '(B, H*W, 6)',
            'segmentation_format': 'Dense prediction',
            'segmentation_shape': '(B, num_seg_classes, H, W)',
            'classification_format': 'Logits',
            'classification_shape': '(B, num_cls_classes)',
            'num_det_classes': self.num_det_classes,
            'num_seg_classes': self.num_seg_classes,
            'num_cls_classes': self.num_cls_classes
        }


# å‘å¾Œå…¼å®¹çš„å–®ä»»å‹™é ­éƒ¨é¡
class DetectionHead(nn.Module):
    """æª¢æ¸¬é ­éƒ¨ (å‘å¾Œå…¼å®¹)"""
    def __init__(self, in_channels, num_classes, num_anchors=9):
        super(DetectionHead, self).__init__()
        self.num_classes = num_classes
        self.num_anchors = num_anchors
        
        self.cls_head = nn.Conv2d(
            in_channels, 
            num_anchors * num_classes, 
            kernel_size=3, 
            padding=1
        )
        self.reg_head = nn.Conv2d(
            in_channels, 
            num_anchors * 4, 
            kernel_size=3, 
            padding=1
        )
    
    def forward(self, x):
        cls_out = self.cls_head(x)
        reg_out = self.reg_head(x)
        return cls_out, reg_out


class SegmentationHead(nn.Module):
    """åˆ†å‰²é ­éƒ¨ (å‘å¾Œå…¼å®¹)"""
    def __init__(self, in_channels, num_classes, feature_scale=4):
        super(SegmentationHead, self).__init__()
        
        self.conv1 = nn.Conv2d(in_channels, 256, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(256)
        self.relu = nn.ReLU(inplace=True)
        
        self.conv2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(256)
        
        self.conv3 = nn.Conv2d(256, num_classes, kernel_size=1)
        self.feature_scale = feature_scale
    
    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        
        x = self.conv2(x)
        x = self.bn2(x)
        x = self.relu(x)
        
        x = self.conv3(x)
        x = F.interpolate(x, scale_factor=self.feature_scale, mode='bilinear', align_corners=True)
        
        return x


class ClassificationHead(nn.Module):
    """åˆ†é¡é ­éƒ¨ (å‘å¾Œå…¼å®¹)"""
    def __init__(self, in_channels, num_classes):
        super(ClassificationHead, self).__init__()
        
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(in_channels, num_classes)
    
    def forward(self, x):
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)
        return x


def create_multitask_head(head_type='unified', **kwargs):
    """
    å¤šä»»å‹™é ­éƒ¨å·¥å» å‡½æ•¸
    
    Args:
        head_type: é ­éƒ¨é¡å‹ 'unified' æˆ– 'separate'
        **kwargs: å…¶ä»–åƒæ•¸
    
    Returns:
        head: é ­éƒ¨ç¶²è·¯å¯¦ä¾‹
    """
    if head_type == 'unified':
        return UnifiedMultiTaskHead(**kwargs)
    elif head_type == 'separate':
        # è¿”å›åˆ†é›¢çš„é ­éƒ¨å­—å…¸
        return {
            'detection': DetectionHead(**kwargs.get('detection', {})),
            'segmentation': SegmentationHead(**kwargs.get('segmentation', {})),
            'classification': ClassificationHead(**kwargs.get('classification', {}))
        }
    else:
        raise ValueError(f"Unsupported head type: {head_type}")


if __name__ == "__main__":
    # æ¸¬è©¦ä»£ç¢¼
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # å‰µå»ºçµ±ä¸€å¤šä»»å‹™é ­éƒ¨
    head = UnifiedMultiTaskHead(
        in_channels=128,
        num_det_classes=10,
        num_seg_classes=21,
        num_cls_classes=10,
        shared_channels=256
    )
    head = head.to(device)
    
    # æ¨¡æ“¬FPNè¼¸å‡º
    batch_size = 2
    fpn_features = {
        'P2': torch.randn(batch_size, 128, 128, 128).to(device),
        'P3': torch.randn(batch_size, 128, 64, 64).to(device),
        'P4': torch.randn(batch_size, 128, 32, 32).to(device),
        'P5': torch.randn(batch_size, 128, 16, 16).to(device)
    }
    
    # å‰å‘å‚³æ’­æ¸¬è©¦
    with torch.no_grad():
        outputs = head(fpn_features, task_type='all')
    
    print("âœ… çµ±ä¸€å¤šä»»å‹™é ­éƒ¨æ¸¬è©¦æˆåŠŸï¼")
    print(f"ğŸ“Š åƒæ•¸çµ±è¨ˆ: {head.get_parameter_count()}")
    print(f"ğŸ“‹ è¼¸å‡ºä¿¡æ¯: {head.get_output_info()}")
    
    print("\nğŸ” è¼¸å‡ºå½¢ç‹€:")
    for task, output in outputs.items():
        print(f"  {task}: {output.shape}")
    
    # æ¸¬è©¦å–®ä»»å‹™æ¨ç†
    print("\nğŸ§ª æ¸¬è©¦å–®ä»»å‹™æ¨ç†:")
    for task in ['detection', 'segmentation', 'classification']:
        with torch.no_grad():
            single_output = head(fpn_features, task_type=task)
        print(f"  {task}: {single_output[task].shape}")