#!/usr/bin/env python3
"""
ä¾åºè¨“ç·´æ¸¬è©¦è…³æœ¬
å¿«é€Ÿæ¸¬è©¦ä¾åºè¨“ç·´æµç¨‹çš„åŸºæœ¬åŠŸèƒ½
"""
import os
import sys
import time
import torch
import torch.nn as nn
from pathlib import Path

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.models.unified_model import create_unified_model
from src.utils.sequential_trainer import create_sequential_trainer


def test_sequential_trainer():
    """æ¸¬è©¦ä¾åºè¨“ç·´å™¨"""
    print("ğŸ§ª æ¸¬è©¦ä¾åºè¨“ç·´å™¨...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ“± ä½¿ç”¨è¨­å‚™: {device}")
    
    # å‰µå»ºæ¨¡å‹
    print("ğŸ—ï¸ å‰µå»ºæ¨¡å‹...")
    model = create_unified_model('lightweight')  # ä½¿ç”¨è¼•é‡åŒ–æ¨¡å‹åŠ å¿«æ¸¬è©¦
    print(f"ğŸ“Š æ¨¡å‹åƒæ•¸: {sum(p.numel() for p in model.parameters()):,}")
    
    # å‰µå»ºæ•¸æ“šåŠ è¼‰å™¨ï¼ˆä½¿ç”¨æ¨¡æ“¬æ•¸æ“šï¼‰
    print("ğŸ“‚ å‰µå»ºæ•¸æ“šåŠ è¼‰å™¨...")
    print("ğŸ”§ å‰µå»ºæ¨¡æ“¬æ•¸æ“šåŠ è¼‰å™¨...")
    dataloaders = create_mock_dataloaders(device)
    
    # å‰µå»ºä¾åºè¨“ç·´å™¨
    print("ğŸ”§ å‰µå»ºä¾åºè¨“ç·´å™¨...")
    trainer = create_sequential_trainer(
        model=model,
        dataloaders=dataloaders,
        ewc_importance=100.0,  # è¼ƒå°çš„EWCæ¬Šé‡
        save_dir='./test_sequential_results',
        device=str(device),
        learning_rate=1e-3,
        adaptive_ewc=True,
        forgetting_threshold=0.1  # è¼ƒå¯¬é¬†çš„éºå¿˜é–¾å€¼
    )
    
    print("âœ… ä¾åºè¨“ç·´å™¨å‰µå»ºæˆåŠŸ")
    
    # æ¸¬è©¦ä¸‰éšæ®µè¨“ç·´ï¼ˆæ¯å€‹éšæ®µåªè¨“ç·´å¾ˆå°‘çš„epochï¼‰
    print("\nğŸš€ é–‹å§‹æ¸¬è©¦ä¸‰éšæ®µè¨“ç·´...")
    
    try:
        # Stage 1: åˆ†å‰²ä»»å‹™
        print("\nğŸ¨ æ¸¬è©¦ Stage 1: åˆ†å‰²ä»»å‹™")
        stage1_metrics = trainer.train_stage(
            stage_name='test_stage1_segmentation',
            task_type='segmentation', 
            epochs=3,  # åªè¨“ç·´3å€‹epoch
            save_checkpoints=False
        )
        print(f"âœ… Stage 1 å®Œæˆï¼ŒæŒ‡æ¨™: {stage1_metrics['main_metric']:.4f}")
        
        # Stage 2: æª¢æ¸¬ä»»å‹™ + EWC  
        print("\nğŸ¯ æ¸¬è©¦ Stage 2: æª¢æ¸¬ä»»å‹™ + EWC")
        stage2_metrics = trainer.train_stage(
            stage_name='test_stage2_detection',
            task_type='detection',
            epochs=3,  # åªè¨“ç·´3å€‹epoch
            save_checkpoints=False
        )
        print(f"âœ… Stage 2 å®Œæˆï¼ŒæŒ‡æ¨™: {stage2_metrics['main_metric']:.4f}")
        
        # æª¢æŸ¥éºå¿˜
        print("\nğŸ” æª¢æŸ¥éºå¿˜ç¨‹åº¦...")
        forgetting_info = trainer.check_forgetting()
        print(f"ğŸ“Š æœ€å¤§éºå¿˜ç¨‹åº¦: {forgetting_info['max_drop']*100:.2f}%")
        print(f"ğŸ¯ éºå¿˜æª¢æŸ¥: {'âœ… é€šé' if forgetting_info['acceptable'] else 'âŒ å¤±æ•—'}")
        
        # Stage 3: åˆ†é¡ä»»å‹™ + EWC
        print("\nğŸ“Š æ¸¬è©¦ Stage 3: åˆ†é¡ä»»å‹™ + EWC")  
        stage3_metrics = trainer.train_stage(
            stage_name='test_stage3_classification',
            task_type='classification',
            epochs=3,  # åªè¨“ç·´3å€‹epoch
            save_checkpoints=False
        )
        print(f"âœ… Stage 3 å®Œæˆï¼ŒæŒ‡æ¨™: {stage3_metrics['main_metric']:.4f}")
        
        # æœ€çµ‚è©•ä¼°
        print("\nğŸ“Š æœ€çµ‚è©•ä¼°æ‰€æœ‰ä»»å‹™...")
        final_metrics = trainer.evaluate_all_tasks()
        for task, metrics in final_metrics.items():
            print(f"  {task}: {metrics['main_metric']:.4f}")
        
        # æœ€çµ‚éºå¿˜æª¢æŸ¥
        final_forgetting = trainer.check_forgetting()
        print(f"\nğŸ” æœ€çµ‚éºå¿˜æª¢æŸ¥:")
        print(f"ğŸ“Š æœ€å¤§éºå¿˜ç¨‹åº¦: {final_forgetting['max_drop']*100:.2f}%")
        print(f"ğŸ¯ ç¸½é«”è©•ä¼°: {'âœ… æˆåŠŸ' if final_forgetting['acceptable'] else 'âŒ å¤±æ•—'}")
        
        # ä¿å­˜æ¸¬è©¦çµæœ
        trainer.save_training_history()
        
        print("\nğŸ‰ ä¾åºè¨“ç·´æ¸¬è©¦å®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


def create_mock_dataloaders(device):
    """å‰µå»ºæ¨¡æ“¬æ•¸æ“šåŠ è¼‰å™¨"""
    print("ğŸ­ å‰µå»ºæ¨¡æ“¬æ•¸æ“šåŠ è¼‰å™¨...")
    
    from torch.utils.data import DataLoader, TensorDataset
    
    batch_size = 4
    num_batches = 5
    
    # æ¨¡æ“¬æ•¸æ“š (ä½¿ç”¨512x512ä»¥åŒ¹é…æ¨¡å‹è¼¸å‡º)
    images = torch.randn(batch_size * num_batches, 3, 512, 512)
    
    # åˆ†å‰²æ•¸æ“š
    seg_targets = torch.randint(0, 21, (batch_size * num_batches, 512, 512))
    seg_dataset = TensorDataset(images, seg_targets)
    seg_train_loader = DataLoader(seg_dataset, batch_size=batch_size, shuffle=True)
    seg_val_loader = DataLoader(seg_dataset, batch_size=batch_size, shuffle=False)
    
    # æª¢æ¸¬æ•¸æ“šï¼ˆç°¡åŒ–ï¼‰
    det_targets = [
        {
            'boxes': torch.rand(2, 4),  # æ¯å€‹åœ–åƒ2å€‹æ¡†
            'labels': torch.randint(0, 10, (2,))
        } for _ in range(batch_size * num_batches)
    ]
    
    class DetectionDataset:
        def __init__(self, images, targets):
            self.images = images
            self.targets = targets
        
        def __len__(self):
            return len(self.images)
        
        def __getitem__(self, idx):
            return self.images[idx], self.targets[idx]
    
    det_dataset = DetectionDataset(images, det_targets)
    det_train_loader = DataLoader(det_dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: x)
    det_val_loader = DataLoader(det_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: x)
    
    # åˆ†é¡æ•¸æ“š
    cls_targets = torch.randint(0, 10, (batch_size * num_batches,))
    cls_dataset = TensorDataset(images, cls_targets)
    cls_train_loader = DataLoader(cls_dataset, batch_size=batch_size, shuffle=True)
    cls_val_loader = DataLoader(cls_dataset, batch_size=batch_size, shuffle=False)
    
    dataloaders = {
        'segmentation_train': seg_train_loader,
        'segmentation_val': seg_val_loader,
        'detection_train': det_train_loader,
        'detection_val': det_val_loader,
        'classification_train': cls_train_loader,
        'classification_val': cls_val_loader
    }
    
    print("âœ… æ¨¡æ“¬æ•¸æ“šåŠ è¼‰å™¨å‰µå»ºå®Œæˆ")
    return dataloaders


def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ§ª ä¾åºè¨“ç·´å¿«é€Ÿæ¸¬è©¦")
    print(f"ğŸ“… æ¸¬è©¦æ™‚é–“: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ Python: {sys.version}")
    print(f"ğŸ”¥ PyTorch: {torch.__version__}")
    
    if torch.cuda.is_available():
        print(f"ğŸš€ CUDA: {torch.version.cuda}")
        print(f"ğŸ“± GPU: {torch.cuda.get_device_name()}")
    else:
        print("ğŸ’» ä½¿ç”¨ CPU")
    
    print("\n" + "=" * 50)
    
    # é‹è¡Œæ¸¬è©¦
    success = test_sequential_trainer()
    
    if success:
        print("\nâœ… ä¾åºè¨“ç·´å™¨æ¸¬è©¦é€šéï¼")
        print("ğŸ”„ ä¾åºè¨“ç·´æµç¨‹è¨­ç½®å®Œæˆï¼")
        print("\nğŸ“‹ è¨“ç·´è¨ˆç•«:")
        print("Stage 1: åˆ†å‰²ä»»å‹™ (è¨˜éŒ„åŸºæº–)")
        print("Stage 2: æª¢æ¸¬ä»»å‹™ + EWC")
        print("Stage 3: åˆ†é¡ä»»å‹™ + EWC")
        print("\nâœ… Phase 3 å¯¦ç¾å®Œæˆï¼æº–å‚™é€²å…¥ Phase 4: è©•ä¼°èˆ‡å„ªåŒ–")
        return 0
    else:
        print("\nâŒ ä¾åºè¨“ç·´å™¨æ¸¬è©¦å¤±æ•—ï¼")
        return 1


if __name__ == "__main__":
    sys.exit(main())