#!/usr/bin/env python3
"""
é è¨“ç·´é©—è­‰è…³æœ¬
åœ¨é–‹å§‹å®Œæ•´è¨“ç·´å‰é©—è­‰æ‰€æœ‰é—œéµçµ„ä»¶
"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import time
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.models.unified_model import create_unified_model
from src.datasets.unified_dataloader import create_unified_dataloaders
from src.utils.sequential_trainer import SequentialTrainer
from src.utils.ewc import create_ewc_handler, ewc_loss


class PreTrainingValidator:
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.results = {}
        
    def print_header(self, title):
        """æ‰“å°æ¸¬è©¦æ¨™é¡Œ"""
        print(f"\n{'='*60}")
        print(f"ğŸ§ª {title}")
        print(f"{'='*60}\n")
        
    def print_result(self, test_name, passed, details=""):
        """æ‰“å°æ¸¬è©¦çµæœ"""
        icon = "âœ…" if passed else "âŒ"
        status = "PASS" if passed else "FAIL"
        print(f"{icon} {test_name}: {status}")
        if details:
            print(f"   {details}")
            
    def test_data_loading(self):
        """æ¸¬è©¦æ‰€æœ‰ä¸‰å€‹ä»»å‹™çš„æ•¸æ“šåŠ è¼‰"""
        self.print_header("æ•¸æ“šåŠ è¼‰æ¸¬è©¦")
        
        try:
            # å‰µå»ºæ•¸æ“šåŠ è¼‰å™¨
            dataloaders = create_unified_dataloaders(
                './data', 
                batch_size=4, 
                num_workers=0
            )
            
            # æ¸¬è©¦æª¢æ¸¬ä»»å‹™æ•¸æ“š
            det_loader = dataloaders['train'].get_task_loader('detection')
            det_batch = next(iter(det_loader))
            
            if isinstance(det_batch, list) and len(det_batch) == 2:
                images, targets = det_batch
                det_pass = (
                    torch.is_tensor(images) and 
                    isinstance(targets, list) and
                    len(targets) == images.shape[0]
                )
                self.print_result(
                    "æª¢æ¸¬æ•¸æ“šåŠ è¼‰", 
                    det_pass,
                    f"æ‰¹æ¬¡æ ¼å¼: [{images.shape}, {len(targets)} targets]"
                )
            else:
                self.print_result("æª¢æ¸¬æ•¸æ“šåŠ è¼‰", False, "éŒ¯èª¤çš„æ‰¹æ¬¡æ ¼å¼")
                
            # æ¸¬è©¦åˆ†å‰²ä»»å‹™æ•¸æ“š
            seg_loader = dataloaders['train'].get_task_loader('segmentation')
            seg_batch = next(iter(seg_loader))
            
            if isinstance(seg_batch, (list, tuple)) and len(seg_batch) == 2:
                images, masks = seg_batch
                # è™•ç†listæ ¼å¼çš„masks
                if isinstance(masks, list):
                    seg_pass = (
                        torch.is_tensor(images) and 
                        len(masks) == images.shape[0] and
                        all(torch.is_tensor(m) for m in masks)
                    )
                    self.print_result(
                        "åˆ†å‰²æ•¸æ“šåŠ è¼‰", 
                        seg_pass,
                        f"æ‰¹æ¬¡æ ¼å¼: [{images.shape}, {len(masks)} masks]"
                    )
                else:
                    seg_pass = (
                        torch.is_tensor(images) and 
                        torch.is_tensor(masks) and
                        masks.shape[0] == images.shape[0]
                    )
                    self.print_result(
                        "åˆ†å‰²æ•¸æ“šåŠ è¼‰", 
                        seg_pass,
                        f"æ‰¹æ¬¡æ ¼å¼: [{images.shape}, {masks.shape}]"
                    )
            else:
                self.print_result("åˆ†å‰²æ•¸æ“šåŠ è¼‰", False, "éŒ¯èª¤çš„æ‰¹æ¬¡æ ¼å¼")
                
            # æ¸¬è©¦åˆ†é¡ä»»å‹™æ•¸æ“š
            cls_loader = dataloaders['train'].get_task_loader('classification')
            cls_batch = next(iter(cls_loader))
            
            if isinstance(cls_batch, (list, tuple)) and len(cls_batch) == 2:
                images, targets = cls_batch
                # è™•ç†å­—å…¸æ ¼å¼çš„targets
                if isinstance(targets, dict) and 'labels' in targets:
                    labels = targets['labels']
                    cls_pass = torch.is_tensor(labels) and labels.shape[0] == images.shape[0]
                    self.print_result(
                        "åˆ†é¡æ•¸æ“šåŠ è¼‰", 
                        cls_pass,
                        f"æ‰¹æ¬¡æ ¼å¼: [{images.shape}, labels={labels.shape}]"
                    )
                else:
                    cls_pass = torch.is_tensor(targets) and targets.shape[0] == images.shape[0]
                    self.print_result(
                        "åˆ†é¡æ•¸æ“šåŠ è¼‰", 
                        cls_pass,
                        f"æ‰¹æ¬¡æ ¼å¼: [{images.shape}, {targets.shape if torch.is_tensor(targets) else type(targets)}]"
                    )
            else:
                self.print_result("åˆ†é¡æ•¸æ“šåŠ è¼‰", False, "éŒ¯èª¤çš„æ‰¹æ¬¡æ ¼å¼")
                
            return dataloaders
            
        except Exception as e:
            self.print_result("æ•¸æ“šåŠ è¼‰", False, f"éŒ¯èª¤: {str(e)}")
            return None
            
    def test_evaluation_functions(self, dataloaders):
        """æ¸¬è©¦æ‰€æœ‰è©•ä¼°å‡½æ•¸"""
        self.print_header("è©•ä¼°å‡½æ•¸æ¸¬è©¦")
        
        try:
            # å‰µå»ºæ¨¡å‹å’Œè¨“ç·´å™¨
            model = create_unified_model('default')
            trainer = SequentialTrainer(
                model=model,
                dataloaders=dataloaders,
                ewc_importance=1000.0,
                save_dir='./test_output',
                device=self.device
            )
            
            # æ¸¬è©¦æª¢æ¸¬è©•ä¼°
            try:
                det_loader = dataloaders['val'].get_task_loader('detection')
                det_metrics = trainer._validate_detection(det_loader)
                self.print_result(
                    "æª¢æ¸¬è©•ä¼°å‡½æ•¸", 
                    True,
                    f"mAP: {det_metrics['main_metric']:.4f}"
                )
            except Exception as e:
                self.print_result("æª¢æ¸¬è©•ä¼°å‡½æ•¸", False, f"éŒ¯èª¤: {str(e)}")
                
            # æ¸¬è©¦åˆ†å‰²è©•ä¼°
            try:
                seg_loader = dataloaders['val'].get_task_loader('segmentation')
                seg_metrics = trainer._validate_segmentation(seg_loader)
                self.print_result(
                    "åˆ†å‰²è©•ä¼°å‡½æ•¸", 
                    True,
                    f"mIoU: {seg_metrics['main_metric']:.4f}"
                )
            except Exception as e:
                self.print_result("åˆ†å‰²è©•ä¼°å‡½æ•¸", False, f"éŒ¯èª¤: {str(e)}")
                
            # æ¸¬è©¦åˆ†é¡è©•ä¼°
            try:
                cls_loader = dataloaders['val'].get_task_loader('classification')
                cls_metrics = trainer._validate_classification(cls_loader)
                self.print_result(
                    "åˆ†é¡è©•ä¼°å‡½æ•¸", 
                    True,
                    f"æº–ç¢ºç‡: {cls_metrics['main_metric']:.4f}"
                )
            except Exception as e:
                self.print_result("åˆ†é¡è©•ä¼°å‡½æ•¸", False, f"éŒ¯èª¤: {str(e)}")
                
        except Exception as e:
            self.print_result("è©•ä¼°å‡½æ•¸", False, f"åˆå§‹åŒ–éŒ¯èª¤: {str(e)}")
            
    def test_ewc_flow(self, dataloaders):
        """æ¸¬è©¦EWCè¨ˆç®—æµç¨‹"""
        self.print_header("EWCæµç¨‹æ¸¬è©¦")
        
        try:
            # å‰µå»ºæ¨¡å‹å’ŒEWCè™•ç†å™¨
            model = create_unified_model('default').to(self.device)
            ewc_handler = create_ewc_handler(model, importance=1000.0)
            
            # æ¸¬è©¦FisherçŸ©é™£è¨ˆç®—
            try:
                seg_loader = dataloaders['train'].get_task_loader('segmentation')
                # ä½¿ç”¨è¼ƒå°‘çš„æ¨£æœ¬é€²è¡Œæ¸¬è©¦
                small_loader = DataLoader(
                    seg_loader.dataset, 
                    batch_size=4, 
                    shuffle=False,
                    num_workers=0,
                    collate_fn=seg_loader.collate_fn if hasattr(seg_loader, 'collate_fn') else None
                )
                
                start_time = time.time()
                task_id = ewc_handler.finish_task(small_loader, verbose=False)
                fisher_time = time.time() - start_time
                
                self.print_result(
                    "FisherçŸ©é™£è¨ˆç®—", 
                    True,
                    f"ä»»å‹™ID: {task_id}, è¨ˆç®—æ™‚é–“: {fisher_time:.2f}ç§’"
                )
            except Exception as e:
                self.print_result("FisherçŸ©é™£è¨ˆç®—", False, f"éŒ¯èª¤: {str(e)}")
                
            # æ¸¬è©¦EWCæå¤±è¨ˆç®—
            try:
                # å‰µå»ºå‡çš„ç•¶å‰æå¤±
                current_loss = torch.tensor(1.0, requires_grad=True).to(self.device)
                
                # è¨ˆç®—EWCæå¤±
                total_loss, ewc_penalty = ewc_loss(current_loss, ewc_handler)
                
                ewc_pass = (
                    torch.is_tensor(total_loss) and 
                    total_loss.requires_grad and
                    ewc_penalty is not None
                )
                
                self.print_result(
                    "EWCæå¤±è¨ˆç®—", 
                    ewc_pass,
                    f"ç¸½æå¤±: {total_loss.item():.4f}, EWCæ‡²ç½°: {ewc_penalty:.4f}"
                )
            except Exception as e:
                self.print_result("EWCæå¤±è¨ˆç®—", False, f"éŒ¯èª¤: {str(e)}")
                
            # æ¸¬è©¦é˜²éºå¿˜æª¢æŸ¥
            try:
                trainer = SequentialTrainer(
                    model=model,
                    dataloaders=dataloaders,
                    ewc_importance=1000.0,
                    save_dir='./test_output',
                    device=self.device,
                    adaptive_ewc=True
                )
                
                # è¨­ç½®åŸºæº–æ€§èƒ½
                trainer.baseline_performance['segmentation'] = 0.8
                
                # æ¸¬è©¦æª¢æŸ¥éºå¿˜
                all_metrics = trainer.evaluate_all_tasks()
                forgetting_detected = trainer._check_catastrophic_forgetting(all_metrics)
                
                self.print_result(
                    "é˜²éºå¿˜æª¢æŸ¥é‚è¼¯", 
                    True,
                    f"æª¢æ¸¬åˆ°éºå¿˜: {forgetting_detected}"
                )
            except Exception as e:
                self.print_result("é˜²éºå¿˜æª¢æŸ¥é‚è¼¯", False, f"éŒ¯èª¤: {str(e)}")
                
        except Exception as e:
            self.print_result("EWCæµç¨‹", False, f"åˆå§‹åŒ–éŒ¯èª¤: {str(e)}")
            
    def test_model_compatibility(self, dataloaders):
        """æ¸¬è©¦æ¨¡å‹å…¼å®¹æ€§"""
        self.print_header("æ¨¡å‹å…¼å®¹æ€§æ¸¬è©¦")
        
        try:
            model = create_unified_model('default').to(self.device)
            model.eval()
            
            # æ¸¬è©¦ä¸‰ç¨®ä»»å‹™çš„å‰å‘å‚³æ’­
            with torch.no_grad():
                # æª¢æ¸¬ä»»å‹™
                det_loader = dataloaders['val'].get_task_loader('detection')
                det_batch = next(iter(det_loader))
                if isinstance(det_batch, list) and len(det_batch) == 2:
                    images, _ = det_batch
                    images = images.to(self.device)
                    outputs = model(images, task_type='detection')
                    det_pass = 'detection' in outputs and torch.is_tensor(outputs['detection'])
                    self.print_result(
                        "æª¢æ¸¬ä»»å‹™å‰å‘å‚³æ’­", 
                        det_pass,
                        f"è¼¸å‡ºå½¢ç‹€: {outputs['detection'].shape}"
                    )
                
                # åˆ†å‰²ä»»å‹™
                seg_loader = dataloaders['val'].get_task_loader('segmentation')
                seg_batch = next(iter(seg_loader))
                if isinstance(seg_batch, (list, tuple)) and len(seg_batch) == 2:
                    images, _ = seg_batch
                    images = images.to(self.device)
                    outputs = model(images, task_type='segmentation')
                    seg_pass = 'segmentation' in outputs and torch.is_tensor(outputs['segmentation'])
                    self.print_result(
                        "åˆ†å‰²ä»»å‹™å‰å‘å‚³æ’­", 
                        seg_pass,
                        f"è¼¸å‡ºå½¢ç‹€: {outputs['segmentation'].shape}"
                    )
                
                # åˆ†é¡ä»»å‹™
                cls_loader = dataloaders['val'].get_task_loader('classification')
                cls_batch = next(iter(cls_loader))
                if isinstance(cls_batch, (list, tuple)) and len(cls_batch) == 2:
                    images, _ = cls_batch
                    images = images.to(self.device)
                    outputs = model(images, task_type='classification')
                    cls_pass = 'classification' in outputs and torch.is_tensor(outputs['classification'])
                    self.print_result(
                        "åˆ†é¡ä»»å‹™å‰å‘å‚³æ’­", 
                        cls_pass,
                        f"è¼¸å‡ºå½¢ç‹€: {outputs['classification'].shape}"
                    )
                    
            # æ¸¬è©¦GPUè¨˜æ†¶é«”ä½¿ç”¨
            if self.device.type == 'cuda':
                memory_used = torch.cuda.memory_allocated() / 1024**3  # GB
                memory_reserved = torch.cuda.memory_reserved() / 1024**3  # GB
                self.print_result(
                    "GPUè¨˜æ†¶é«”ä½¿ç”¨", 
                    True,
                    f"å·²ä½¿ç”¨: {memory_used:.2f}GB, å·²ä¿ç•™: {memory_reserved:.2f}GB"
                )
                
            # æ¸¬è©¦æ¢¯åº¦è¨ˆç®—
            model.train()
            optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
            
            # ç°¡å–®çš„æ¢¯åº¦æ¸¬è©¦
            images = torch.randn(2, 3, 512, 512).to(self.device)
            outputs = model(images, task_type='all')
            
            # å‰µå»ºå‡çš„æå¤±
            loss = sum(output.mean() for output in outputs.values())
            loss.backward()
            
            # æª¢æŸ¥æ¢¯åº¦
            has_grad = any(p.grad is not None and p.grad.abs().max() > 0 for p in model.parameters())
            self.print_result(
                "æ¢¯åº¦è¨ˆç®—æ­£å¸¸", 
                has_grad,
                "æ‰€æœ‰åƒæ•¸éƒ½æœ‰æœ‰æ•ˆæ¢¯åº¦"
            )
            
            optimizer.zero_grad()
            
        except Exception as e:
            self.print_result("æ¨¡å‹å…¼å®¹æ€§", False, f"éŒ¯èª¤: {str(e)}")
            
    def run_all_tests(self):
        """é‹è¡Œæ‰€æœ‰æ¸¬è©¦"""
        print("\n" + "="*60)
        print("ğŸš€ é è¨“ç·´é©—è­‰é–‹å§‹")
        print("="*60)
        
        # æ¸¬è©¦æ•¸æ“šåŠ è¼‰
        dataloaders = self.test_data_loading()
        
        if dataloaders:
            # æ¸¬è©¦è©•ä¼°å‡½æ•¸
            self.test_evaluation_functions(dataloaders)
            
            # æ¸¬è©¦EWCæµç¨‹
            self.test_ewc_flow(dataloaders)
            
            # æ¸¬è©¦æ¨¡å‹å…¼å®¹æ€§
            self.test_model_compatibility(dataloaders)
        
        print("\n" + "="*60)
        print("ğŸ¯ æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")
        print("="*60)
        
        # æª¢æŸ¥æ˜¯å¦æ‰€æœ‰æ¸¬è©¦éƒ½é€šé
        if dataloaders:
            print("\nâœ… æ‰€æœ‰æ¸¬è©¦é€šéï¼å¯ä»¥å®‰å¿ƒé–‹å§‹å®Œæ•´è¨“ç·´ï¼")
            print("\nå»ºè­°è¨“ç·´å‘½ä»¤:")
            print("CUDA_VISIBLE_DEVICES=1 python scripts/sequential_training.py \\")
            print("  --batch_size 16 \\")
            print("  --stage1_epochs 50 \\")
            print("  --stage2_epochs 40 \\")
            print("  --stage3_epochs 30 \\")
            print("  --ewc_importance 1000 \\")
            print("  --adaptive_ewc")
        else:
            print("\nâŒ æœ‰æ¸¬è©¦å¤±æ•—ï¼Œè«‹å…ˆä¿®å¾©å•é¡Œå†é–‹å§‹è¨“ç·´ï¼")


if __name__ == "__main__":
    validator = PreTrainingValidator()
    validator.run_all_tests()